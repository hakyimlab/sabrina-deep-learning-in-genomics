{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9qB7ynvSK5a"
      },
      "source": [
        "## GENETIC MEDICINE DEEP LEARNING HACKATHON 2022\n",
        "\n",
        "### ENFORMER USAGE NOTEBOOK - PARTICIPANT\n",
        "\n",
        "**Authors**: Saideep Gona, Temidayo Adeluwa\n",
        "\n",
        "**Acknowledgement**:\n",
        "- Boxiang Liu\n",
        "- Festus Nyasimi (for providing us with Predixcan predictions)\n",
        "\n",
        "**Date**: Saturday April 2, 2022"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rb_ShvB9E8yM"
      },
      "source": [
        "Copyright 2021 DeepMind Technologies Limited\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kXQjDxgdwUmW"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, we explore how Enformer can be used to predict the expression of protein-coding genes. We utilized some code from the [original Enformer usage colab notebook](https://colab.research.google.com/github/deepmind/deepmind_research/blob/master/enformer/enformer-usage.ipynb). Here, we showcase how the Enformer model can be used to predict gene expression on a GEUVADIS/1000 genomes dataset, and compare the predictions with true expression.\n",
        "\n",
        "**\"Effective gene expression prediction from sequence by integrating long-range interactions\"**\n",
        "\n",
        "Å½iga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R. Ledsam, Agnieszka Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, David R. Kelley"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "si-w2NPretDg"
      },
      "source": [
        "### Steps\n",
        "\n",
        "This notebook demonstrates how to\n",
        "- Prepare inputs for Enformer to make predictions\n",
        "- Make predictions with Enformer and produce figures\n",
        "- Compare predictions with true expression"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wCCJsjaHwTYC"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NqR7ol3rxrtM"
      },
      "source": [
        "Google Colab gives us some GPU access. This limited GPU is available to anyone with a Google account, who has signed up to use Colaboratory. We will begin by changing the runtime type to GPU. Follow the instruction below by clicking on \"Runtime -> Change runtime type -> GPU\" in the menu bar below the title of this notebook.\n",
        "\n",
        "**Start the colab kernel with GPU**: Runtime -> Change runtime type -> GPU\n",
        "\n",
        "\n",
        "Below, we import tensorflow as tf, and check that the runtime has been changed to GPU."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dbfKKYSgouvH"
      },
      "source": [
        "kipoiseq is a package that helps us to extract sequences from fasta files given some intervals. We will install the package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg8hcb45wqMM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# Make sure the GPU is enabled \n",
        "assert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -> Change runtime type -> GPU'\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can ignore the pyYAML error\n",
        "!echo $SHELL\n",
        "!echo $PATH"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq7uxLyqiXfj"
      },
      "source": [
        "Biopython is a python package that helps us do many bioinfomatic analysis in python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO3AtZ-Y50Nw",
        "outputId": "ed234327-29b9-4d20-c68b-f4a290baad9b"
      },
      "outputs": [],
      "source": [
        "#!pip install Biopython"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MCDk7UQPG0Lr"
      },
      "source": [
        "### Setting up our environments"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QTi5WYntpAoA"
      },
      "source": [
        "We need to have some packages imported to help us do cool stuff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRI9KisU11bM"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub # for interacting with saved models and tensorflow hub\n",
        "import joblib\n",
        "import gzip # for manipulating compressed files\n",
        "import kipoiseq # for manipulating fasta files\n",
        "from kipoiseq import Interval # same as above, really\n",
        "import pyfaidx # to index our reference genome file\n",
        "import pandas as pd # for manipulating dataframes\n",
        "import numpy as np # for numerical computations\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "import matplotlib as mpl # for plotting\n",
        "import seaborn as sns # for plotting\n",
        "import pickle # for saving large objects\n",
        "import os, sys # functions for interacting with the operating system\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BOCpY-KSWfT2"
      },
      "source": [
        "**Optional**\n",
        "\n",
        "You may want to store your results. Google Drive gives about 15gb worth of storage space, used for all your files and emails.\n",
        "\n",
        "Here, you can mount your Google Drive using the next line of code. You will need to provide permission access.\n",
        "\n",
        "The line after that will automatically create a folder called \"Enformer_Hackathon_2022\" in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTzF3SHvWYFY",
        "outputId": "4e8c150c-36e1-4ae0-be1f-9acac53236a0"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIOrkP_aXM7f"
      },
      "outputs": [],
      "source": [
        "#!mkdir -p \"/content/drive/MyDrive/Enformer_Hackathon_2022/results/\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lSnTLAQQta4w"
      },
      "source": [
        "\n",
        "Next,"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d_xe-kLopGfA"
      },
      "source": [
        "We want to define some paths to save downloaded files for the duration of this notebook. These will be wiped off by Google as soon as we are done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0F1A9AaCrkQ"
      },
      "outputs": [],
      "source": [
        "transform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\n",
        "model_path = 'https://tfhub.dev/deepmind/enformer/1'\n",
        "fasta_file = '/home/s1mi/enformer_tutorial/genome.fa'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kzSr0Jwbpqae"
      },
      "source": [
        "We may inspect the tracks used to train the model. The CAGE prediction corresponding to B lymphoblastoid cell line is index 5110. We use B lymphoblastoid cell line predictions here because that is the cell line used to generate GEUVADIS gene expression data. You can copy the https link, paste in another tab in your browser and look through the large txt file for other tracks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "OlE6JAVfI08a",
        "outputId": "1c912c07-7a2e-46c4-fa8d-33ba698f030d"
      },
      "outputs": [],
      "source": [
        "# Download targets from Basenji2 dataset\n",
        "# Cite: Kelley et al Cross-species regulatory sequence activity prediction. PLoS Comput. Biol. 16, e1008050 (2020).\n",
        "targets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n",
        "df_targets = pd.read_csv(targets_txt, sep='\\t')\n",
        "df_targets[df_targets.index==5110]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8ZhswycGux3"
      },
      "source": [
        "### Download files"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dowTJknFJOHu"
      },
      "source": [
        "\n",
        "We need to download some files. Give it a moment.\n",
        "We will download the following files:\n",
        "- The reference genome fasta file (we will also index this file in the process)\n",
        "- A text file for the transcription start sites for each chromosome\n",
        "- Per chromosome files that has annotation for the genes\n",
        "- A compressed file that contains the variant bed files for the genes and their locations.\n",
        "\n",
        "Credit to Genome Reference Consortium: https://www.ncbi.nlm.nih.gov/grc\n",
        "\n",
        "Schneider et al 2017 http://dx.doi.org/10.1101/gr.213611.116: Evaluation of GRCh38 and de novo haploid genome assemblies demonstrates the enduring quality of the reference assembly"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GvWsL_rhTJkE"
      },
      "source": [
        "Make a data directory, and download the necessary bed files and chromosome annotation files"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eztL6gRyX5WG"
      },
      "source": [
        "**NB:** You may decide to download these files into your \"/content/drive/MyDrive/Enformer_Hackathon_2022/\" directory. **You don't need to do this**. But if you want permanent access to the files we use in this notebook, you can change the path from \"/home/s1mi/enformer_tutorial/\" to \"/content/drive/MyDrive/Enformer_Hackathon_2022/\", and modify what you need accordingly."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LmnnSfMYYfOO"
      },
      "source": [
        "The next line of code will download the reference genome fasta file and index this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PJ8US7ojKKJ",
        "outputId": "09b1c79a-2b86-4555-f16b-36313b4d5dd9"
      },
      "outputs": [],
      "source": [
        "# reference genome and indexed\n",
        "#!wget -O - https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz | gunzip -c > {fasta_file}\n",
        "#pyfaidx.Faidx(fasta_file)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r9aglFj2vOpB"
      },
      "source": [
        "The next lines of code will download the variation bed files, and we have created links to help us download the variation bed files for each chromosome, for each gene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "WzCvzPVjbRI_",
        "outputId": "9de5f0ba-973b-441a-a498-618066bdd40f"
      },
      "outputs": [],
      "source": [
        "chrom_bed_downloads = pd.read_csv(\"https://uchicago.box.com/shared/static/du77wf31li38tciv8imivwu57svae03p.csv\")\n",
        "chrom_bed_downloads.index = chrom_bed_downloads[\"chroms\"]\n",
        "\n",
        "chrom_bed_downloads.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "skTRacN7bTS4"
      },
      "source": [
        "We will define a function to help us download bed variation files for a given gene or list of genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PtjgX9vdtkk"
      },
      "outputs": [],
      "source": [
        "def download_chrom_beds(chromosome, genes, downloads_table=chrom_bed_downloads):\n",
        "  '''\n",
        "  Downloads bed/variation files for a chromosome and list of genes\n",
        "  '''\n",
        "\n",
        "  link = downloads_table.loc[str(chromosome), \"link\"]\n",
        "  chr_which = 'chr' + chromosome\n",
        "  for gene in genes:\n",
        "    if os.path.exists('/home/s1mi/enformer_tutorial/individual_beds/chr' + chromosome + '/chr' + chromosome + '_' + gene + '.bed'): # if the file is in the folder, no need to download again\n",
        "      continue\n",
        "    !curl -L {link} --output /home/s1mi/enformer_tutorial/chr_{chromosome}_bed.tar.gz && cd /home/s1mi/enformer_tutorial && tar -zxf /home/s1mi/enformer_tutorial/chr_{chromosome}_bed.tar.gz ./individual_beds/{chr_which}/{chr_which}_{gene}.bed\n",
        "\n",
        "    # remove the download tar.gz file\n",
        "    !rm /home/s1mi/enformer_tutorial/chr_{chromosome}_bed.tar.gz"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "esOW5oCBdA1q"
      },
      "source": [
        "We don't need this function yet. But we can test out how it works.\n",
        "\n",
        "Assuming we want to download the variation files for 'ERAP1', which is located on chromosome 5...\n",
        "\n",
        "This will download the bed file into /home/s1mi/enformer_tutorial/individual_beds/chr5/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wmTNeBqdAJ2",
        "outputId": "fbd87143-2693-44b9-941b-b39d856d99f0"
      },
      "outputs": [],
      "source": [
        "download_chrom_beds(chromosome = '5', genes=['ERAP1', 'ERAP2'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9GakybEle4Kf"
      },
      "source": [
        "And when you need the file, you can read it in like..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "px72l50Me8ft",
        "outputId": "b098aa73-1e39-4410-e165-e28f689c42c5"
      },
      "outputs": [],
      "source": [
        "erap1_variations = pd.read_table('/home/s1mi/enformer_tutorial/individual_beds/chr5/chr5_ERAP1.bed', sep='\\t')\n",
        "erap1_variations.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zDSrPVKSeZW7"
      },
      "source": [
        "You can pass in a list of genes as long as they are all located on that chromosome."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4qX4ZOm7crbE"
      },
      "source": [
        "In the next block of code, we download the TSS for each chromosome and the genes in that chromosome, as wells as the per chromosome gene annotations. We need this information to estimate predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1v40z8k5q1f",
        "outputId": "bd64a030-c1c7-4377-f7d9-91834054774b"
      },
      "outputs": [],
      "source": [
        "#!curl -L https://uchicago.box.com/shared/static/perc3uabzzd267cbp8zc0inwgrmur7pu.gz --output /home/s1mi/enformer_tutorial/chr_tss.tar.xz && cd /home/s1mi/enformer_tutorial/ && tar -zxf /home/s1mi/enformer_tutorial/chr_tss.tar.xz\n",
        "\n",
        "#!mkdir -p /home/s1mi/enformer_tutorial/gene_chroms #creates a folder to hold our files\n",
        "#!curl -L https://uchicago.box.com/shared/static/e2kiwrjlgqqio0pc37a2iz7l5bqbv57u.gz --output /home/s1mi/enformer_tutorial/gene_chroms/gene_chroms.tar.gz && cd /home/s1mi/enformer_tutorial/gene_chroms/ && tar -zxf /home/s1mi/enformer_tutorial/gene_chroms/gene_chroms.tar.gz\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1HUbUaKeuaYK"
      },
      "source": [
        "### How do we want to go about using Enformer given all these files we just downloaded?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ickvq5_EYpvK"
      },
      "source": [
        "As we know, enformer's input is a single strand genome sequence. Yet, we are interested in predicting on population level data which includes individual-specific variation. To get around this limitation, we will treat each individual as the sum of their haplotypes. Using the phased variant data around each gene (stored in the variant bed files) to modify the reference sequence, we can create two distinct haplotype sequences for each individual. The sum of both of Enformer's haplotype predictions serves as an individual-specific, additive estimate which we can correlate with true predictions. Together, the files we downloaded give us all the information we need to build these haplotype sequences.\n",
        "\n",
        "Althought enformer predicts a wide array of functional output, we will focus here on gene expression in lymphoblastoid cells allowing for correlation against ground truth Geuvadis gene expression data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3nHX2Y37xBEO"
      },
      "source": [
        "There are many functions that we have defined in the next code block. You can explore them later, but for now, simply run the block by clicking on the play button."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Omj-KERcwSdB"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fKGGQIMjtdif"
      },
      "source": [
        "Next, we have some functions that will help us along the way. Classes and methods defined in this code block can be found in the [original Enformer usage colab notebook](https://colab.research.google.com/github/deepmind/deepmind_research/blob/master/enformer/enformer-usage.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "47E4AEgLx1VT",
        "outputId": "e6a400e0-0c95-486c-fa53-a59c20ffd1f1"
      },
      "outputs": [],
      "source": [
        "# @title `Enformer`, `EnformerScoreVariantsNormalized`, `EnformerScoreVariantsPCANormalized`,\n",
        "SEQUENCE_LENGTH = 393216\n",
        "\n",
        "class Enformer:\n",
        "\n",
        "  def __init__(self, tfhub_url):\n",
        "    self._model = hub.load(tfhub_url).model\n",
        "\n",
        "  def predict_on_batch(self, inputs):\n",
        "    predictions = self._model.predict_on_batch(inputs)\n",
        "    return {k: v.numpy() for k, v in predictions.items()}\n",
        "\n",
        "  @tf.function\n",
        "  def contribution_input_grad(self, input_sequence,\n",
        "                              target_mask, output_head='human'):\n",
        "    input_sequence = input_sequence[tf.newaxis]\n",
        "\n",
        "    target_mask_mass = tf.reduce_sum(target_mask)\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(input_sequence)\n",
        "      prediction = tf.reduce_sum(\n",
        "          target_mask[tf.newaxis] *\n",
        "          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n",
        "\n",
        "    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n",
        "    input_grad = tf.squeeze(input_grad, axis=0)\n",
        "    return tf.reduce_sum(input_grad, axis=-1)\n",
        "\n",
        "\n",
        "class EnformerScoreVariantsRaw:\n",
        "\n",
        "  def __init__(self, tfhub_url, organism='human'):\n",
        "    self._model = Enformer(tfhub_url)\n",
        "    self._organism = organism\n",
        "\n",
        "  def predict_on_batch(self, inputs):\n",
        "    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n",
        "    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n",
        "\n",
        "    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n",
        "\n",
        "\n",
        "class EnformerScoreVariantsNormalized:\n",
        "\n",
        "  def __init__(self, tfhub_url, transform_pkl_path,\n",
        "               organism='human'):\n",
        "    assert organism == 'human', 'Transforms only compatible with organism=human'\n",
        "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
        "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
        "      transform_pipeline = joblib.load(f)\n",
        "    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n",
        "\n",
        "  def predict_on_batch(self, inputs):\n",
        "    scores = self._model.predict_on_batch(inputs)\n",
        "    return self._transform.transform(scores)\n",
        "\n",
        "\n",
        "class EnformerScoreVariantsPCANormalized:\n",
        "\n",
        "  def __init__(self, tfhub_url, transform_pkl_path,\n",
        "               organism='human', num_top_features=500):\n",
        "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
        "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
        "      self._transform = joblib.load(f)\n",
        "    self._num_top_features = num_top_features\n",
        "\n",
        "  def predict_on_batch(self, inputs):\n",
        "    scores = self._model.predict_on_batch(inputs)\n",
        "    return self._transform.transform(scores)[:, :self._num_top_features]\n",
        "\n",
        "\n",
        "# TODO(avsec): Add feature description: Either PCX, or full names.\n",
        "\n",
        "\n",
        "# @title `variant_centered_sequences`\n",
        "\n",
        "class FastaStringExtractor:\n",
        "\n",
        "    def __init__(self, fasta_file):\n",
        "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
        "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
        "    #import pd.Interval as Interval\n",
        "    def extract(self, interval: Interval, **kwargs) -> str:\n",
        "        # Truncate interval if it extends beyond the chromosome lengths.\n",
        "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
        "        trimmed_interval = Interval(interval.chrom,\n",
        "                                    max(interval.start, 0),\n",
        "                                    min(interval.end, chromosome_length),\n",
        "                                    )\n",
        "        # pyfaidx wants a 1-based interval\n",
        "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
        "                                          trimmed_interval.start + 1,\n",
        "                                          trimmed_interval.stop).seq).upper()\n",
        "        # Fill truncated values with N's.\n",
        "        pad_upstream = 'N' * max(-interval.start, 0)\n",
        "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
        "        return pad_upstream + sequence + pad_downstream\n",
        "\n",
        "    def close(self):\n",
        "        return self.fasta.close()\n",
        "\n",
        "\n",
        "def one_hot_encode(sequence):\n",
        "  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "# @title `plot_tracks`\n",
        "\n",
        "def plot_tracks(tracks, interval, height=1.5):\n",
        "  fig, axes = plt.subplots(len(tracks), 1, figsize=(20, height * len(tracks)), sharex=True)\n",
        "  for ax, (title, y) in zip(axes, tracks.items()):\n",
        "    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y)\n",
        "    ax.set_title(title)\n",
        "    sns.despine(top=True, right=True, bottom=True)\n",
        "  ax.set_xlabel(str(interval))\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5t0sQ5Tuek2B"
      },
      "source": [
        "Here, we define some utility functions for ourselves, to help us make predictions and analyse our predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmvG1Ta46Xf3"
      },
      "outputs": [],
      "source": [
        "import Bio\n",
        "\n",
        "from Bio.Seq import Seq\n",
        "def create_rev_complement(dna_string):\n",
        "    return(str(Seq(dna_string).reverse_complement()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UaDZTBQR-ys"
      },
      "outputs": [],
      "source": [
        "def prepare_for_quantify_prediction_per_TSS(predictions, gene, tss_df):\n",
        "\n",
        "  '''\n",
        "\n",
        "  Parameters:\n",
        "          predicitions (A numpy array): All predictions from the track\n",
        "          gene (a gene name, character): a gene\n",
        "          tss_df: a list of dataframe of genes and their transcription start sites\n",
        "  Returns:\n",
        "          A dictionary of cage experiment predictions and a list of transcription start sites\n",
        "\n",
        "  '''\n",
        "\n",
        "  output = dict()\n",
        "  for tdf in tss_df:\n",
        "    if gene not in tdf.genes.values:\n",
        "      continue\n",
        "    gene_tss_list = tdf[tdf.genes == gene].txStart_Sites.apply(str).values\n",
        "    gene_tss_list = [t.split(', ') for t in gene_tss_list]\n",
        "    gene_tss_list = [int(item) for nestedlist in gene_tss_list for item in nestedlist]\n",
        "    gene_tss_list = list(set(gene_tss_list))\n",
        "  output['cage_predictions'] = predictions[:, 5110] # a numpy array\n",
        "  output['gene_TSS'] = gene_tss_list # a list\n",
        "\n",
        "\n",
        "  return(output) # a dictionary\n",
        "\n",
        "def quantify_prediction_per_TSS(low_range, TSS, cage_predictions):\n",
        "\n",
        "  '''\n",
        "  Parameters:\n",
        "          low_range (int): The lower interval\n",
        "          TSS (list of integers): A list of TSS for a gene\n",
        "          cage_predictions: A 1D numpy array or a vector of predictions from enformer corresponding to track 5110 or CAGE predictions\n",
        "  Returns:\n",
        "          A dictionary of gene expression predictions for each TSS for a gene\n",
        "    '''\n",
        "  tss_predictions = dict()\n",
        "  for tss in TSS:\n",
        "    bin_start = low_range + ((768 + 320) * 128)\n",
        "    count = -1\n",
        "    while bin_start < tss:\n",
        "      bin_start = bin_start + 128\n",
        "      count += 1\n",
        "    if count >= len(cage_predictions)-1:\n",
        "      continue\n",
        "    cage_preds = cage_predictions[count - 1] + cage_predictions[count] + cage_predictions[count + 1]\n",
        "    tss_predictions[tss] = cage_preds\n",
        "\n",
        "  return(tss_predictions)\n",
        "\n",
        "def collect_intervals(chromosomes = [\"22\"], gene_list=None):\n",
        "\n",
        "  '''\n",
        "    Parameters :\n",
        "      chromosomes : a list of chromosome numbers; each element should be a string format\n",
        "      gene_list : a list of genes; the genes should be located on those chromosomes\n",
        "\n",
        "    Returns :\n",
        "      A dictionary of genes (from gene_list) and their intervals within their respective chromosomes\n",
        "  '''\n",
        "\n",
        "  gene_intervals = {} # Collect intervals for our genes of interest\n",
        "\n",
        "  for chrom in chromosomes:\n",
        "    with open(\"/home/s1mi/enformer_tutorial/gene_chroms/gene_\"+ chrom + \".txt\", \"r\") as chrom_genes:\n",
        "      for line in chrom_genes:\n",
        "        split_line = line.strip().split(\"\\t\")\n",
        "        gene_intervals[split_line[2]] = [\n",
        "                                          split_line[0],\n",
        "                                          int(split_line[3]),\n",
        "                                          int(split_line[4])\n",
        "                                        ]\n",
        "\n",
        "  if isinstance(gene_list, list): # if the user has supplied a list of genes they are interested in\n",
        "    use_genes = dict((k, gene_intervals[k]) for k in gene_list if k in gene_intervals)\n",
        "    return(use_genes)\n",
        "  elif isinstance(gene_list, type(None)):\n",
        "    return(gene_intervals)\n",
        "\n",
        "\n",
        "def run_predictions(gene_intervals, tss_dataframe, individuals_list=None):\n",
        "  '''\n",
        "  Parameters :\n",
        "    gene_intervals : the results from calling `collect_intervals`\n",
        "    tss_dataframe : a list of the TSSs dataframes i.e. the TSS for the genes in the chromosomes\n",
        "    individuals_list : a list of individuals on which we want to make predictions; defaults to None\n",
        "\n",
        "  Returns :\n",
        "    A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n",
        "  '''\n",
        "\n",
        "  gene_output = dict()\n",
        "  gene_predictions = dict()\n",
        "\n",
        "  for gene in gene_intervals.keys():\n",
        "    gene_interval = gene_intervals[gene]\n",
        "    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n",
        "                                        gene_interval[1],\n",
        "                                        gene_interval[2]) # creates an interval to select the right sequences\n",
        "    target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n",
        "    window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n",
        "    try:\n",
        "      cur_gene_vars = pd.read_csv(\"/home/s1mi/enformer_tutorial/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n",
        "    except:\n",
        "      continue\n",
        "    individual_results = dict()\n",
        "    individual_prediction = dict()\n",
        "\n",
        "    if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n",
        "      use_individuals = individuals_list\n",
        "    elif isinstance(individuals_list, type(None)):\n",
        "      use_individuals = cur_gene_vars.columns[4:]\n",
        "\n",
        "    for individual in use_individuals:\n",
        "      print('Currently on gene {}, and predicting on individual {}...'.format(gene, individual))\n",
        "      # two haplotypes per individual\n",
        "      haplo_1 = list(target_fa[:])\n",
        "      haplo_2 = list(target_fa[:])\n",
        "\n",
        "      ref_mismatch_count = 0\n",
        "      for i,row in cur_gene_vars.iterrows():\n",
        "\n",
        "        geno = row[individual].split(\"|\")\n",
        "        if (row[\"POS\"]-window_coords.start-1) >= len(haplo_2):\n",
        "          continue\n",
        "        if (row[\"POS\"]-window_coords.start-1) < 0:\n",
        "          continue\n",
        "        if geno[0] == \"1\":\n",
        "          haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n",
        "        if geno[1] == \"1\":\n",
        "          haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n",
        "\n",
        "      # predict on the individual's two haplotypes\n",
        "      prediction_1 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_1))[np.newaxis])['human'][0]\n",
        "      prediction_2 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_2))[np.newaxis])['human'][0]\n",
        "\n",
        "      temp_predictions = [prediction_1[:, 5110], prediction_2[:, 5110]] # CAGE predictions we are interested in\n",
        "      individual_prediction[individual] = temp_predictions\n",
        "\n",
        "      # Calculate TSS CAGE expression which correspond to column 5110 of the predictions above\n",
        "      temp_list = list()\n",
        "\n",
        "      pred_prepared_1 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_1, gene=gene, tss_df=tss_dataframe)\n",
        "      tss_predictions_1 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_1['gene_TSS'], cage_predictions=pred_prepared_1['cage_predictions'])\n",
        "\n",
        "      pred_prepared_2 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_2, gene=gene, tss_df=tss_dataframe)\n",
        "      tss_predictions_2 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_2['gene_TSS'], cage_predictions=pred_prepared_2['cage_predictions'])\n",
        "\n",
        "      temp_list.append(tss_predictions_1)\n",
        "      temp_list.append(tss_predictions_2) # results here are a dictionary for each TSS for each haplotype\n",
        "\n",
        "      individual_results[individual] = temp_list # save for the individual\n",
        "\n",
        "    gene_output[gene] = individual_results\n",
        "    gene_predictions[gene] = individual_prediction\n",
        "\n",
        "  return([gene_output, gene_predictions])\n",
        "\n",
        "\n",
        "def collect_target_intervals(gene_intervals):\n",
        "\n",
        "  '''\n",
        "  Returns a dictionary of Interval objects (from kipoiseq) for each gene corresponding to the locations of the gene\n",
        "  '''\n",
        "\n",
        "  target_intervals_dict = dict()\n",
        "\n",
        "  for gene in gene_intervals.keys():\n",
        "    gene_interval = gene_intervals[gene]\n",
        "    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n",
        "                                        gene_interval[1],\n",
        "                                        gene_interval[2])\n",
        "    target_intervals_dict[gene] = target_interval\n",
        "\n",
        "  return(target_intervals_dict)\n",
        "\n",
        "def prepare_for_plot_tracks(gene, individual, all_predictions, chromosome=['22']):\n",
        "\n",
        "  '''\n",
        "  This returns a dictionary of gene tracks and gene intervals, prepared for the function plot_tracks.\n",
        "\n",
        "  Parameters:\n",
        "    - gene\n",
        "    - individual\n",
        "    - all_predictions\n",
        "  '''\n",
        "\n",
        "  haplo_predictions = all_predictions[gene][individual]\n",
        "  gene_tracks = {gene + ' | ' + individual + ' | haplotype 1': np.log10(1 + haplo_predictions[0]),\n",
        "                gene + ' | ' + individual + ' | haplotype 2': np.log10(1 + haplo_predictions[1])}\n",
        "\n",
        "  gene_intervals = collect_intervals(chromosomes=chromosome, gene_list=[gene])\n",
        "  gene_intervals = collect_target_intervals(gene_intervals)\n",
        "\n",
        "  output = dict()\n",
        "  output['gene_tracks'] = gene_tracks\n",
        "  output['gene_intervals'] = gene_intervals[gene]\n",
        "\n",
        "  return(output)\n",
        "\n",
        "def check_individuals(path_to_bed_file, list_of_individuals):\n",
        "\n",
        "  '''\n",
        "  Checks if an individual is missing in bed variation files.\n",
        "  These individuals should be removed prior to training\n",
        "  '''\n",
        "\n",
        "  myfile = open(path_to_bed_file, 'r')\n",
        "  myline = myfile.readline()\n",
        "  bed_names = myline.split('\\t')[4:]\n",
        "  myfile.close()\n",
        "\n",
        "  if set(list_of_individuals).issubset(set(bed_names)) == False:\n",
        "    missing = list(set(list_of_individuals).difference(bed_names))\n",
        "    print('This (or these) individual(s) is/are not present: {}'.format(missing))\n",
        "  else:\n",
        "    missing = []\n",
        "    print('All individuals are present in the bed file.')\n",
        "\n",
        "  return(missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OCS8CUtIQ-V"
      },
      "outputs": [],
      "source": [
        "def plot_predixcan_vs_geuvadis(interested_gene, interested_individuals, geuvadis_expression, predixcan_expression):\n",
        "\n",
        "  '''\n",
        "  Show a plot and return correlation coefficient\n",
        "  '''\n",
        "  # from predixcan expression\n",
        "  df_predixcan = predixcan_expression[predixcan_expression.gene_name == interested_gene].loc[:,interested_individuals]\n",
        "  # from enformer\n",
        "  df_geuvadis = geuvadis_expression[geuvadis_expression.gene_name == interested_gene].loc[:,interested_individuals]\n",
        "\n",
        "  # concatenate both\n",
        "  df_all = pd.concat([df_predixcan, df_geuvadis], axis=0)\n",
        "  df_all.index = ['Predixcan', 'GEUVADIS']\n",
        "\n",
        "  # plotting\n",
        "  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='red').set(title='Predixcan vs. GEUVADIS predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n",
        "\n",
        "  # correlation coefficient\n",
        "  corr_coef = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n",
        "\n",
        "  return([df_all, corr_coef])\n",
        "\n",
        "def plot_enformer_vs_predixcan(prediction_results, interested_gene, interested_individuals, predixcan_expression, how='sum'):\n",
        "\n",
        "  '''\n",
        "  Show a plot and return correlation coefficient\n",
        "  '''\n",
        "\n",
        "  enformer_predictions = dict()\n",
        "\n",
        "  for gene, individuals in prediction_results[0].items():\n",
        "    temp_individual = dict()\n",
        "    for individual, haplo_predictions in individuals.items():\n",
        "      temp = list()\n",
        "      for i in range(0, len(haplo_predictions[0])):\n",
        "        temp.append(list(haplo_predictions[0].values())[i] + list(haplo_predictions[1].values())[i])\n",
        "      if how == 'sum':\n",
        "        temp_individual[individual] = np.sum(temp)\n",
        "      elif how == 'max':\n",
        "        temp_individual[individual] = np.max(temp)\n",
        "    enformer_predictions[gene] = temp_individual\n",
        "\n",
        "  # from predixcan expression\n",
        "  df_predixcan = predixcan_expression[predixcan_expression.gene_name == interested_gene].loc[:,interested_individuals]\n",
        "  # from enformer\n",
        "  df_enformer = pd.DataFrame(enformer_predictions[interested_gene], index=[0]).loc[:, df_predixcan.columns]\n",
        "\n",
        "  # concatenate both\n",
        "  df_all = pd.concat([df_enformer, df_predixcan], axis=0)\n",
        "  df_all.index = ['Enformer', 'Predixcan']\n",
        "\n",
        "  # plotting\n",
        "  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='red').set(title='Predixcan vs. Enformer predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n",
        "\n",
        "  # correlation coefficient\n",
        "  corr_coef_predix = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n",
        "\n",
        "  return([df_all, corr_coef_predix])\n",
        "\n",
        "\n",
        "def plot_enformer_vs_geuvadis(prediction_results, interested_gene, interested_individuals, geuvadis_expression, how='sum'):\n",
        "\n",
        "  '''\n",
        "  Show a plot and return correlation coefficient\n",
        "  '''\n",
        "\n",
        "  enformer_predictions = dict()\n",
        "\n",
        "  for gene, individuals in prediction_results[0].items():\n",
        "    temp_individual = dict()\n",
        "    for individual, haplo_predictions in individuals.items():\n",
        "      temp = list()\n",
        "      for i in range(0, len(haplo_predictions[0])):\n",
        "        temp.append(list(haplo_predictions[0].values())[i] + list(haplo_predictions[1].values())[i])\n",
        "      if how == 'sum':\n",
        "        temp_individual[individual] = np.sum(temp)\n",
        "      elif how == 'max':\n",
        "        temp_individual[individual] = np.max(temp)\n",
        "    enformer_predictions[gene] = temp_individual\n",
        "\n",
        "  # from geuvadis expression\n",
        "  df_geuvadis = geuvadis_expression[geuvadis_expression.gene_name == interested_gene].loc[:,interested_individuals]\n",
        "  #df_enformer = np.transpose(pd.DataFrame(enformer_predictions)).loc[:, df_geuvadis.columns]\n",
        "  df_enformer = pd.DataFrame(enformer_predictions[interested_gene], index=[0]).loc[:, df_geuvadis.columns]\n",
        "\n",
        "  # concatenate both\n",
        "  df_all = pd.concat([df_enformer, df_geuvadis], axis=0)\n",
        "  df_all.index = ['Enformer', 'GEUVADIS']\n",
        "\n",
        "  # plotting\n",
        "  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='blue').set(title='Enformer vs. Geuvadis predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n",
        "\n",
        "  # correlation coefficient\n",
        "  corr_coef_geu = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n",
        "\n",
        "  return([df_all, corr_coef_geu])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zEwfoz3cwOzt"
      },
      "source": [
        "## Make predictions on the GEUVADIS dataset."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RAfzoHdZfEG5"
      },
      "source": [
        "Here, we will begin to make predictions. Excited?!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AkFtKNsHfIXM"
      },
      "source": [
        "We still need the model itself. The model has been graciously hosted on [Tensorflow Hub](https://tfhub.dev/deepmind/enformer/1), which hosts many other models too. You can click on the link and explore. When you click the link, you can see that the model is about 892 Mb large. Quite big.\n",
        "We will use the url to the model to download and use it here.\n",
        "\n",
        "Earlier, we defined an Enformer class (see the codes section). We will load the model into this class. The model has been trained and the weights are freely available. All we need to do is to load this model and use it. Neat.\n",
        "\n",
        "We also defined a class FastaStringExtractor, that can help us extract raw sequences from fasta files given the intervals we want. We will make use of this class too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC-pgC35DgnL"
      },
      "outputs": [],
      "source": [
        "model = Enformer(model_path) # here we load the model architecture.\n",
        "\n",
        "fasta_extractor = FastaStringExtractor(fasta_file) # we define a class called fasta_extractor to help us extra raw sequence data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wJdaa3-yXv2U"
      },
      "source": [
        "### **EXERCISE 1:**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OmtHW_QJg4Lh"
      },
      "source": [
        "For evaluation, we need to **sum the predictions around each unique TSS for a given gene**. We will be using this a lot so it is important that we define what it means. Essentially, for a gene with one TSS, we take the sum of predicitions of the 128 bp output bin containing the TSS and its two immediate neighboring bins. We do this for each haplotype and each TSS to give TSS-level predictions.\n",
        "\n",
        "To get individual-level estimates for a whole gene, we sum each haplotype TSS estimate to summarize TSS-level predictions per individual, and then take either the sum or max of TSS-level predictions to summarize at the gene level.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tg1PFEEkYce"
      },
      "source": [
        "There are many genes and many individuals in our datasets. To make illustration simpler, we will use four genes, *ERAP1*, *ERAP2*, *NUDT2*, and *PEX6*, located on chromosome 5, 5, 9, and 6 respectively. We will use predictions for 10 randomly selected individuals located in the bed files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyNBcZQAs_Xf",
        "outputId": "2791e673-9da7-4b9d-8531-7c794185fca7"
      },
      "outputs": [],
      "source": [
        "download_chrom_beds(chromosome = \"5\", genes = ['ERAP1', 'ERAP2'])\n",
        "download_chrom_beds(chromosome = \"9\", genes = ['NUDT2'])\n",
        "download_chrom_beds(chromosome = \"6\", genes = ['PEX6'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ds35eLyFkpW_"
      },
      "source": [
        "\n",
        "\n",
        "Here, we read into a dataframe the TSS (transcription start sites) per gene for the chromosomes we are interested in. The dataframe has three columns. The first contains the genes, and the second contains the TSS(s) for that gene, and the third contains the strand information. We are interested in genes located on chromosomes 5, 6 and 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "12B11Qg17qNg",
        "outputId": "d8a76934-e1f0-40ba-8c1c-48f60601cd1a"
      },
      "outputs": [],
      "source": [
        "chr5_tss = pd.read_table('/home/s1mi/enformer_tutorial/tss_by_chr/chr5_tss_by_gene.txt', sep='\\t')\n",
        "chr6_tss = pd.read_table('/home/s1mi/enformer_tutorial/tss_by_chr/chr6_tss_by_gene.txt', sep='\\t')\n",
        "chr9_tss = pd.read_table('/home/s1mi/enformer_tutorial/tss_by_chr/chr9_tss_by_gene.txt', sep='\\t')\n",
        "\n",
        "chr9_tss.head(10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5ptVaruczVmu"
      },
      "source": [
        "#### Preparing inputs for Enformer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk9gcH7ilfNS"
      },
      "source": [
        "Now that we have downloaded the genetic information that we need, we want to prepare the inputs for Enformer.\n",
        "\n",
        "We need the following\n",
        "- The genes we want to predict for\n",
        "- The genomic interval for these genes\n",
        "- Information about the transcription start sites for these genes\n",
        "- The individuals we want to predict for"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V5kc9pgHw_lT"
      },
      "source": [
        "We have a utility function that helps to define the intervals of a gene, and resize this interval to make it acceptable for Enformer. Enformer needs a specific, defined sequence length. We use the **collect_intervals** function. The result is a dictionary that contains chromosome and interval information for each gene.\n",
        "\n",
        "For example, let's explore ERAP1..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmtK1AduwVyF",
        "outputId": "512f71af-1df8-42d8-8c16-317a030f1bda"
      },
      "outputs": [],
      "source": [
        "ERAP1_intervals = collect_intervals(chromosomes=['5'], gene_list=['ERAP1'])\n",
        "ERAP1_target_intervals = collect_target_intervals(ERAP1_intervals)\n",
        "ERAP1_intervals, ERAP1_target_intervals"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YpAAPfdf0_4U"
      },
      "source": [
        "**ERAP1_target_intervals** is an Interval object created using the kipoiseq package we installed earlier. It is used during predictions, and we don't need to know the methods of this object for the purpose of the next questions.\n",
        "\n",
        "However, we have similar information in **ERAP1_intervals**, which is a python dictionary of lists. For the questions below, we will use the **ERAP1_intervals** object."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QQvEa5uox0AY"
      },
      "source": [
        "#### ***Question 1a***\n",
        "\n",
        "What is the size of this interval? *Hint*: Look at the **ERAP1_intervals**, and remember that Python is 0-based indexed. You need to access the **key** of this dictionary, which is the gene name, and for the value, which is a list, you can access the first element using 0, the second element using 1, and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXfO_fJKyUh8",
        "outputId": "e5072587-661b-4a61-84f7-911e106c9bc4"
      },
      "outputs": [],
      "source": [
        "ERAP1_intervals['ERAP1'][2] - ERAP1_intervals['ERAP1'][1] # your answers go in the ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LGGact2OyVEX"
      },
      "source": [
        "#### ***Note***\n",
        "\n",
        "You can roughly confirm this interval by going to the UCSC genome browser or Ensemble genome browser. We have provided a link for UCSC genome browser's interval length [for ERAP1 here](https://genome.ucsc.edu/cgi-bin/hgTracks?db=hg19&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr5%3A96096517%2D96143648&hgsid=1316458921_99pz1X7GNzmiEg0WV1q2UmDp9nSB). Click on this link, the answer is right at the top of the browser."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tVoSjqFM2ack"
      },
      "source": [
        "Enformer takes in a defined sequence length. When we provide a gene and collect its intervals, we need to resize this interval to be acceptable for Enformer. Here, we will use the Intervals object define earlier, **ERAP1_target_intervals**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZxbszVczowr",
        "outputId": "3c37002b-46af-42fe-e540-be19b23afee3"
      },
      "outputs": [],
      "source": [
        "ERAP1_target_interval_resized = ERAP1_target_intervals['ERAP1'].resize(SEQUENCE_LENGTH)\n",
        "ERAP1_target_interval_resized"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mlhKASQ33Mxk"
      },
      "source": [
        "#### ***Question 1b***\n",
        "\n",
        "What is the length of this interval? Simply run the next line of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1iwYZmn0cos",
        "outputId": "c0a53c51-4692-4a47-ca57-237d27497a95"
      },
      "outputs": [],
      "source": [
        "ERAP1_target_interval_resized.end - ERAP1_target_interval_resized.start"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F3eU3hDG2Ezp"
      },
      "source": [
        "Essentially, we resized the length of the gene and pad it with the native sequences to the left and to the right, such that the length of the input sequence is 393216, and we can imagine our gene right at the center of this wider interval. This is the same interval length used to train ENCODE data to build Enformer. Since this value is pre-define, we really cannot change it. This is information that Enformer uses to make very good predictions. Below, we confirm that this is true."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rMouw-A4OaD",
        "outputId": "db229dc2-931e-4e86-8005-87d09104762d"
      },
      "outputs": [],
      "source": [
        "(ERAP1_target_interval_resized.end - ERAP1_target_interval_resized.start) == SEQUENCE_LENGTH"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JBaF9mVF4ZuN"
      },
      "source": [
        "#### Making predictions with Enformer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "akzbZpTwr_Z8"
      },
      "source": [
        "We will select 10 individuals (we have provided 10 randomly sample individuals for ease), and use four genes, *ERAP1*, *ERAP2*, *NUDT2*, and *PEX6*, located on chromosome 5, 5, 9, and 6 respectively\n",
        "\n",
        "We will collect the intervals that correspond to these genes, collect the sequences for that interval from the reference fasta file, loop through each individual's variations in the bed files we provided, switch around the variations for each haplotype and predict expression.\n",
        "\n",
        "Eventually, for each individual, we should have predictions corresponding to each haplotype. We expect that since the haplotypes are different, the predictions should vary too.\n",
        "\n",
        "Additionally, we need the TSS for these genes. Remember that we read in the dataframe earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ch-R_6ceA9U"
      },
      "outputs": [],
      "source": [
        "exercise_1_genes = ['ERAP1', 'NUDT2', 'ERAP2', 'PEX6'] # our gene of interest\n",
        "#exercise_1_gene = ['NUDT2', 'ERAP2'] # our gene of interest\n",
        "\n",
        "exercise_1_individuals = ['NA11992', 'NA19235', 'NA20770', 'HG00232', 'HG00342', 'NA20502', 'NA19189', 'HG00108', 'HG00380', 'NA12872'] # individuals we are interested in\n",
        "\n",
        "exercise_1_chromosomes = ['5', '9', '6'] # the gene is on chromosome 5\n",
        "\n",
        "exercise_1_tss_dfs = [chr5_tss, chr9_tss, chr6_tss] # we use the TSS information"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pcJsEimhkM19"
      },
      "source": [
        "#### ***QUESTION 2***\n",
        "What is the id of the 8th individual? Hint: Python used 0-based indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi7vBE7_kWiq",
        "outputId": "82dff590-70e8-4b4d-915e-1c01ba9eb60c"
      },
      "outputs": [],
      "source": [
        "print('The 8th individual is {}'.format(exercise_1_individuals[7])) # your code goes into the ellipsis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CBF_RbmpDVg4"
      },
      "source": [
        "It is possible to have individuals not present in our variation bed files for some reasons. So, we will do some sanity checks.\n",
        "\n",
        "Using the **check_individuals** functions, we will check if all these individuals are present in the bed file for that gene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaY-1jN1DQUa",
        "outputId": "23d7a637-f302-4080-c820-9570566d6967"
      },
      "outputs": [],
      "source": [
        "missing_1 = check_individuals(\"/home/s1mi/enformer_tutorial/individual_beds/chr9/chr9_NUDT2.bed\", list_of_individuals = exercise_1_individuals)\n",
        "missing_2 = check_individuals(\"/home/s1mi/enformer_tutorial/individual_beds/chr5/chr5_ERAP2.bed\", list_of_individuals = exercise_1_individuals)\n",
        "missing_3 = check_individuals(\"/home/s1mi/enformer_tutorial/individual_beds/chr5/chr5_ERAP1.bed\", list_of_individuals = exercise_1_individuals)\n",
        "missing_4 = check_individuals(\"/home/s1mi/enformer_tutorial/individual_beds/chr6/chr6_PEX6.bed\", list_of_individuals = exercise_1_individuals)\n",
        "missing_1, missing_2, missing_3, missing_4"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "43LEWbEeD9wD"
      },
      "source": [
        "It looks like all the individuals are present. Very nice! We are good to go."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUTk1Nu29XN"
      },
      "source": [
        "To make predictions, we first collect the intervals for the genes we want to predict for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08p4PHSfDQXR",
        "outputId": "47f26096-7eb7-4c09-aaeb-76e23e96f50a"
      },
      "outputs": [],
      "source": [
        "exercise_1_interval = collect_intervals(chromosomes=exercise_1_chromosomes, gene_list=exercise_1_genes) # here, we collect the intervals for that gene\n",
        "exercise_1_interval"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "575MiElt3GME"
      },
      "source": [
        "Next, we use the **run_predictions** function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj6m7POZsMen",
        "outputId": "47b8f525-7b44-41df-9bc8-cfa848fd1744"
      },
      "outputs": [],
      "source": [
        "exercise_1_predictions = run_predictions(gene_intervals=exercise_1_interval, tss_dataframe=exercise_1_tss_dfs, individuals_list=exercise_1_individuals) # here we make predictions and save it."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AgdIMqvgbqCE"
      },
      "source": [
        "**NB:** If you intend to make predictions across many individuals and genes, it will be faster if you have larger GPU access. For now, we are using limited GPU. So, we have to limit our predictions."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vuurhYXWx7Ha"
      },
      "source": [
        "Quite fast right? Very nice.\n",
        "\n",
        "Our prediction object, **exercise_1_predictions** is a list of length two.\n",
        "- The first item in the list corresponds to the sum of predictions around each unique TSS, for each haplotype, for each individual, for each gene.\n",
        "\n",
        "- The second item in the list corresponds to the CAGE:B lymphoblastoid cell line predictions across all 128bp bins for each haplotype, for each individual, for the genes. We will use the second item for plotting the tracks.\n",
        "\n",
        "Let us take a look at the object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbxJgPj_y2aZ",
        "outputId": "823cd61e-0778-485c-9fec-e64e401a2e77"
      },
      "outputs": [],
      "source": [
        "print(\"The exercise_1_predictions object is a {} of length {}.\".format(type(exercise_1_predictions).__name__, len(exercise_1_predictions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OppjdpoEzgp4"
      },
      "outputs": [],
      "source": [
        "exercise_1_predictions[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "msgREjLw4iyI"
      },
      "source": [
        "#### Plotting the CAGE:B lymphoblastoid cell line tracks"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x9J80rqIxTQ6"
      },
      "source": [
        "Next, we will plot the tracks. We have already defined two helper functions, **prepare_for_plot_tracks** and **plot_tracks** to plot the expression along the TSS for a gene, for an individual and for each haplotype."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PIiox4C9mlGf"
      },
      "source": [
        "For NUDT2..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "RSl35IvTmkf5",
        "outputId": "cba34a3d-586a-4b86-f738-badedc155d37"
      },
      "outputs": [],
      "source": [
        "temp = prepare_for_plot_tracks(gene=exercise_1_genes[1], individual=exercise_1_individuals[0], all_predictions=exercise_1_predictions[1], chromosome=['9'])\n",
        "plot_tracks(tracks=temp['gene_tracks'], interval=temp['gene_intervals'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_CyZlK2gZ4"
      },
      "source": [
        "Looks nice!\n",
        "\n",
        "Although it looks like there is no variation in the predictions for the haplotypes, we can take a look at the actual prediction values across the TSS.\n",
        "\n",
        "The columns are the transcription start sites, and the rows are the haplotypes for the individual. The entries are the sum of the predictions at the *TSS*, at *TSS - 1*, and at the *TSS + 1*.\n",
        "\n",
        "We will look at the first individual, **NA11992**, for **NUDT2**..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "-nL-H30N3Ty2",
        "outputId": "58d37046-c581-4d26-f662-7284c2320253"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(exercise_1_predictions[0][exercise_1_genes[1]][exercise_1_individuals[0]], index=['haplotype_1', 'haplotype_2'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lOgoMacYFA0k"
      },
      "source": [
        "We will look at the first individual, **NA11992**, for **PEX6**...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "pbb8BSj14ubF",
        "outputId": "15b8a889-62a0-4a85-a272-ba02ca66a85e"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(exercise_1_predictions[0][exercise_1_genes[3]][exercise_1_individuals[0]], index=['haplotype_1', 'haplotype_2'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XotUuqfE5Izz"
      },
      "source": [
        "Merely looking at the values, it looks like there are variations in the predictions across the haplotypes and the TSS. We expected some variations because we are predicting expression for each haplotype, which tend to have variations in them. Very nice!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NIqBU-oM5Z7A"
      },
      "source": [
        "## Comparing with true expression from GEUVADIS and with Predixcan\n",
        "\n",
        "We should read in the GEUVADIS and Predixcan predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "YtI6un2DrmgY",
        "outputId": "4fe9f470-89e2-4935-e4fd-0d49d8f8df03"
      },
      "outputs": [],
      "source": [
        "geuvadis_gene_expression = pd.read_table('https://uchicago.box.com/shared/static/5vwc7pjw9qmtv7298c4rc7bcuicoyemt.gz', sep='\\t',\n",
        "                                         dtype={'gene_id': str, 'gene_name':str, 'TargetID':str, 'Chr':str})\n",
        "geuvadis_gene_expression.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "GYt9r9rXDsl3",
        "outputId": "379f904b-a2fb-4184-e4c6-c1177e831f51"
      },
      "outputs": [],
      "source": [
        "predixcan_gene_expression = pd.read_table('https://uchicago.box.com/shared/static/4k68u7x7rxjpoljfdva6qipjxwzd3l0g.txt', sep=' ')\n",
        "predixcan_gene_expression.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sNYzkDH2l4eu"
      },
      "source": [
        "#### ***QUESTION 3a***\n",
        "What is the dimension/size/shape of the **geuvadis_gene_expression** dataframe? Hint: You can use the .shape method on a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtJXDEHhkf_m",
        "outputId": "39658489-75be-4942-dce8-7840cdccbfe4"
      },
      "outputs": [],
      "source": [
        "geuvadis_dimension = geuvadis_gene_expression.shape\n",
        "#print(\"The geuvadis_gene_expression dataframe has {} rows and {} columns\".format(*geuvadis_dimension))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WoEU6jfpm8qg"
      },
      "source": [
        "#### ***QUESTION 4b***\n",
        "What is the dimension/size/shape of the **predixcan_gene_expression** dataframe? Hint: You can use the .shape method on a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bU2_-j0Nmv7",
        "outputId": "95c1343b-16e3-4bf6-ad89-d48e213c2077"
      },
      "outputs": [],
      "source": [
        "predixcan_dimension = predixcan_gene_expression.shape\n",
        "print(\"The predixcan_gene_expression dataframe has {} rows and {} columns\".format(*predixcan_dimension))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PiAQGd3x5kDz"
      },
      "source": [
        "We select the individuals and the gene from the geuvadis_gene_expression dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxceEWei5h-D"
      },
      "outputs": [],
      "source": [
        "erap1_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == exercise_1_genes[0]].loc[:,exercise_1_individuals]\n",
        "nudt2_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == exercise_1_genes[1]].loc[:,exercise_1_individuals]\n",
        "erap2_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == exercise_1_genes[2]].loc[:,exercise_1_individuals]\n",
        "pex6_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == exercise_1_genes[3]].loc[:,exercise_1_individuals]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "9b1CCn4xp7_K",
        "outputId": "5f4daab7-3313-4280-dc46-6d189c1e8801"
      },
      "outputs": [],
      "source": [
        "nudt2_geuvadis_expression"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ0DOLGu6-Pv"
      },
      "source": [
        "We will sum the prediction for both haplotypes for each TSS, and take the sum of the resulting values. The function used here can also take the max instead of the sums."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SqhLqXkUN9oB"
      },
      "source": [
        "We have 3 utility functions to help us\n",
        "- plot_enformer_vs_guevadis\n",
        "- plot_predixcan_vs_geuvadis\n",
        "- plot_enformer_vs_predixcan (if you think this is necessary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "Yo-CXTYsYzwP",
        "outputId": "7739e0d6-0361-4fd6-82e1-7f06eba81cc5"
      },
      "outputs": [],
      "source": [
        "erap1_vs_geu = plot_enformer_vs_geuvadis(prediction_results=exercise_1_predictions, geuvadis_expression=geuvadis_gene_expression,\n",
        "                            interested_gene=exercise_1_genes[0], interested_individuals=exercise_1_individuals, how='sum')\n",
        "print('Correlation coefficient: {}'.format(erap1_vs_geu[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "GbZm5hnMxiSm",
        "outputId": "f86c49af-cc3d-43f8-80ec-062508155318"
      },
      "outputs": [],
      "source": [
        "pex6_vs_geu = plot_enformer_vs_geuvadis(prediction_results=exercise_1_predictions, geuvadis_expression=geuvadis_gene_expression,\n",
        "                            interested_gene=exercise_1_genes[3], interested_individuals=exercise_1_individuals, how='sum')\n",
        "\n",
        "print('Correlation coefficient: {}'.format(pex6_vs_geu[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "FJsQ3pv13On1",
        "outputId": "a7da3825-9b21-4d56-932d-ec635525298a"
      },
      "outputs": [],
      "source": [
        "nudt_vs_geu = plot_enformer_vs_geuvadis(prediction_results=exercise_1_predictions, geuvadis_expression=geuvadis_gene_expression,\n",
        "                            interested_gene=exercise_1_genes[1], interested_individuals=exercise_1_individuals, how='sum')\n",
        "\n",
        "print('Correlation coefficient: {}'.format(nudt_vs_geu[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "lAP1QmIc3SNs",
        "outputId": "82b41343-c295-4b4d-b485-af291495e33f"
      },
      "outputs": [],
      "source": [
        "erap2_vs_geu = plot_enformer_vs_geuvadis(prediction_results=exercise_1_predictions, geuvadis_expression=geuvadis_gene_expression,\n",
        "                            interested_gene=exercise_1_genes[2], interested_individuals=exercise_1_individuals, how='sum')\n",
        "\n",
        "print('Correlation coefficient: {}'.format(erap2_vs_geu[1]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8yAsokG3OSp8"
      },
      "source": [
        "Now, we can see how Predixcan performs on these individuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "jOE8azMSJLy1",
        "outputId": "d245f45e-a45c-4c48-f819-95f7dee22ffb"
      },
      "outputs": [],
      "source": [
        "erap1_predix = plot_predixcan_vs_geuvadis(interested_gene=exercise_1_genes[0], interested_individuals=exercise_1_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\n",
        "print('The correlation coefficient: {}'.format(erap1_predix[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "5nQCkP_HKzfy",
        "outputId": "50e712e1-702c-4cd2-df84-40edb2e1dcb8"
      },
      "outputs": [],
      "source": [
        "pex6_predix = plot_predixcan_vs_geuvadis(interested_gene=exercise_1_genes[3], interested_individuals=exercise_1_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\n",
        "print('The correlation coefficient: {}'.format(pex6_predix[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "JvKohJ0JtRud",
        "outputId": "a93acdf3-c3d4-40bb-f19e-ad481e9b063d"
      },
      "outputs": [],
      "source": [
        "erap2_predix = plot_predixcan_vs_geuvadis(interested_gene=exercise_1_genes[2], interested_individuals=exercise_1_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\n",
        "print('The correlation coefficient: {}'.format(erap2_predix[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "vSDGAwEPMHb1",
        "outputId": "845939e4-e00a-4897-a490-1534f73fc5b6"
      },
      "outputs": [],
      "source": [
        "nudt2_predix = plot_predixcan_vs_geuvadis(interested_gene=exercise_1_genes[1], interested_individuals=exercise_1_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\n",
        "print('The correlation coefficient: {}'.format(nudt2_predix[1]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mcsCAaHr6trO"
      },
      "source": [
        "Quite neat and impressive!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aUcFxfIVcYQ8"
      },
      "source": [
        "## **EXERCISE 2**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rQFhBSYEccPn"
      },
      "source": [
        "In this exercise, you will get your hands dirty, and run Enformer on your gene(s) of interest.\n",
        "\n",
        "1. Select your favorite gene(s). **Note that the more genes you use, the longer it will take to run**.\n",
        "\n",
        "2. Randomly select 10 individuals, just because we don't have all the computational power.\n",
        "\n",
        "3. Run predictions\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0TJ83gfespsC"
      },
      "source": [
        "We only have data for a finite set of genes (sorry!). Here is a list of available genes you can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojYzDhyXsoyf",
        "outputId": "944612e4-f856-4624-e9a6-a025205575a4"
      },
      "outputs": [],
      "source": [
        "!curl -L https://uchicago.box.com/shared/static/x8d7dx1ykefz49ep6sxot42v44sfvcv5.tsv --output /home/s1mi/enformer_tutorial/all_genes.tsv\n",
        "\n",
        "with open(\"/home/s1mi/enformer_tutorial/all_genes.tsv\", \"r\") as ag:\n",
        "  all_genes = [line.strip() for line in ag]\n",
        "print(len(all_genes))\n",
        "print(\"First 5 genes all_genes:\", all_genes[0:5])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gWhcF-xFc9dD"
      },
      "source": [
        "1. Select your genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSK9hJYYc6E_",
        "outputId": "105b0902-3b12-4878-ddda-8c2d322d2473"
      },
      "outputs": [],
      "source": [
        "my_genes = ['ATAD3A']\n",
        "print(\"My gene(s) is/are {}\".format(', '.join(my_genes)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XnISrVgQdieQ"
      },
      "source": [
        "2. Read in the TSS txt files where those chromosome are located. If you have genes located on more than one chromosome, copy the **pd.read_table** line for each chromosome you have, and replace the chromosome number (ellipses) as appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTXPHpqlegiL"
      },
      "outputs": [],
      "source": [
        "my_chromosomes = ['1'] # put in the chromosomes where the genes are located. Just the numbers will do, or you can put them in as a string type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygWfp2kvc6aA"
      },
      "outputs": [],
      "source": [
        "my_tss_list = []\n",
        "for chr in my_chromosomes:\n",
        "  chr = str(chr)\n",
        "  bed_file = '/home/s1mi/enformer_tutorial/tss_by_chr/chr{}_tss_by_gene.txt'.format(chr)\n",
        "  my_tss_list.append(pd.read_table(bed_file, sep='\\t')) # we read in the TSSs for each chromosome, and put them into a list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq4H0Z2JfLXo"
      },
      "source": [
        "3. Randomly select 10 individuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GevPFhe9fSVk",
        "outputId": "a3e1a0eb-3488-4634-8465-334ba3572e0e"
      },
      "outputs": [],
      "source": [
        "# let us set a seed to randomly select 10 individuals\n",
        "np.random.seed(2021)  # replace ... with an integer you want\n",
        "\n",
        "number_of_individuals = 10\n",
        "\n",
        "my_individuals = np.random.choice(a=geuvadis_gene_expression.columns[6:-1], size=number_of_individuals, replace=False) # individuals we are interested in\n",
        "my_individuals"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v3zCA5wVfnd1"
      },
      "source": [
        "4. We want to make sure that we have complete variation information for all 10 individuals.\n",
        "\n",
        "First, we need to download the variation bed files for these individuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdnqWGKv9Y_m",
        "outputId": "25de8c34-1e39-499c-bd99-7c2810b38eb3"
      },
      "outputs": [],
      "source": [
        "download_chrom_beds(chromosome='1', genes=my_genes) # remember that the genes should be on that chromosome, and you can use this code for each chromosome you have."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n-9n2unx9rH7"
      },
      "source": [
        "Read in the variation bed files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4ebpe0yc6aB",
        "outputId": "f18fb43a-ca0b-4ad6-e571-f419e19347e0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "my_missing_list = list()\n",
        "for chr in my_chromosomes:\n",
        "  for gene in my_genes:\n",
        "    chr = str(chr)\n",
        "    file_path = '/home/s1mi/enformer_tutorial/individual_beds/chr' + chr + '/chr' + chr + '_' + gene + '.bed'\n",
        "    if not os.path.exists(file_path):\n",
        "      continue\n",
        "    my_missing_list.append(check_individuals(file_path, my_individuals))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ4_gOHOnqP4"
      },
      "source": [
        "#### ***QUESTION 4***\n",
        "Are there missing individuals? All answers, based on your results are correct. If there are missing individuals, can you remove them? You can add new code blocks as you like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0tT96v1oAVT",
        "outputId": "06b151c0-3d6f-4f4a-f59b-d7246fa4c7f1"
      },
      "outputs": [],
      "source": [
        "my_missing_list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RcG_Ld8voRC8"
      },
      "source": [
        "It looks like we are almost set to make predictions.\n",
        "\n",
        "5. Make predictions. First, we will collect the intervals for the genes we want, check the object and make sure we are on the right track. Next, we will call our **run_predictions** function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEKb5gSnocIy",
        "outputId": "d651b2b2-d50d-4af3-e9f9-39722bdc7203"
      },
      "outputs": [],
      "source": [
        "my_intervals = collect_intervals(chromosomes= my_chromosomes, gene_list= my_genes) # here, we collect the intervals for that gene; replace ... with the right objects\n",
        "my_intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbxPuGlgocIz",
        "outputId": "3c7c3263-c304-4c31-ba57-d74ea116b251"
      },
      "outputs": [],
      "source": [
        "my_predictions = run_predictions(gene_intervals= my_intervals, tss_dataframe= my_tss_list, individuals_list=my_individuals)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UzjC2sck-8Ah"
      },
      "source": [
        "At this point, we will leave you to make your own plots..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "atad3a_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == my_genes[0]].loc[:,my_individuals]\n",
        "atad3a_vs_geu = plot_enformer_vs_geuvadis(prediction_results=my_predictions, geuvadis_expression=geuvadis_gene_expression, \n",
        "                            interested_gene=my_genes[0], interested_individuals=my_individuals, how='sum')\n",
        "print('Correlation coefficient: {}'.format(atad3a_vs_geu[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "atad3a_predix = plot_predixcan_vs_geuvadis(interested_gene=my_genes[0], interested_individuals=my_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\n",
        "print('The correlation coefficient: {}'.format(atad3a_predix[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Average Haplotype vs Average Epigenome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get ERAP2 interval:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ERAP2_intervals = collect_intervals(chromosomes=['5'], gene_list=['ERAP2'])\n",
        "ERAP2_target_intervals = collect_target_intervals(ERAP2_intervals)\n",
        "ERAP2_intervals, ERAP2_target_intervals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select random individual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rand_individual = np.random.choice(a=geuvadis_gene_expression.columns[6:-1], size=1, replace=False) # individuals we are interested in\n",
        "rand_individual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run predictions (returns average epigenome):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_predictions = run_predictions(gene_intervals= my_intervals, tss_dataframe= my_tss_list, individuals_list=my_individuals)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Omj-KERcwSdB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml-python",
      "language": "python",
      "name": "ml-python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
