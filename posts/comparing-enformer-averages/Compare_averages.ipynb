{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Make sure the GPU is enabled \n",
    "assert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -> Change runtime type -> GPU'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import tensorflow_hub as hub # for interacting with saved models and tensorflow hub\n",
    "import joblib\n",
    "import gzip # for manipulating compressed files\n",
    "import kipoiseq # for manipulating fasta files\n",
    "from kipoiseq import Interval # same as above, really\n",
    "import pyfaidx # to index our reference genome file\n",
    "import pandas as pd # for manipulating dataframes\n",
    "import numpy as np # for numerical computations\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import matplotlib as mpl # for plotting\n",
    "import seaborn as sns # for plotting\n",
    "import pickle # for saving large objects\n",
    "import os, sys # functions for interacting with the operating system\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\n",
    "model_path = 'https://tfhub.dev/deepmind/enformer/1'\n",
    "fasta_file = '/home/s1mi/enformer-tutorial/genome.fa'\n",
    "targets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n",
    "df_targets = pd.read_csv(targets_txt, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title `Enformer`, `EnformerScoreVariantsNormalized`, `EnformerScoreVariantsPCANormalized`,\n",
    "SEQUENCE_LENGTH = 393216\n",
    "\n",
    "class Enformer:\n",
    "\n",
    "  def __init__(self, tfhub_url):\n",
    "    self._model = hub.load(tfhub_url).model\n",
    "\n",
    "  def predict_on_batch(self, inputs):\n",
    "    predictions = self._model.predict_on_batch(inputs)\n",
    "    return {k: v.numpy() for k, v in predictions.items()}\n",
    "\n",
    "  @tf.function\n",
    "  def contribution_input_grad(self, input_sequence,\n",
    "                              target_mask, output_head='human'):\n",
    "    input_sequence = input_sequence[tf.newaxis]\n",
    "\n",
    "    target_mask_mass = tf.reduce_sum(target_mask)\n",
    "    with tf.GradientTape() as tape:\n",
    "      tape.watch(input_sequence)\n",
    "      prediction = tf.reduce_sum(\n",
    "          target_mask[tf.newaxis] *\n",
    "          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n",
    "\n",
    "    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n",
    "    input_grad = tf.squeeze(input_grad, axis=0)\n",
    "    return tf.reduce_sum(input_grad, axis=-1)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsRaw:\n",
    "\n",
    "  def __init__(self, tfhub_url, organism='human'):\n",
    "    self._model = Enformer(tfhub_url)\n",
    "    self._organism = organism\n",
    "\n",
    "  def predict_on_batch(self, inputs):\n",
    "    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n",
    "    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n",
    "\n",
    "    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsNormalized:\n",
    "\n",
    "  def __init__(self, tfhub_url, transform_pkl_path,\n",
    "               organism='human'):\n",
    "    assert organism == 'human', 'Transforms only compatible with organism=human'\n",
    "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
    "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
    "      transform_pipeline = joblib.load(f)\n",
    "    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n",
    "\n",
    "  def predict_on_batch(self, inputs):\n",
    "    scores = self._model.predict_on_batch(inputs)\n",
    "    return self._transform.transform(scores)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsPCANormalized:\n",
    "\n",
    "  def __init__(self, tfhub_url, transform_pkl_path,\n",
    "               organism='human', num_top_features=500):\n",
    "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
    "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
    "      self._transform = joblib.load(f)\n",
    "    self._num_top_features = num_top_features\n",
    "\n",
    "  def predict_on_batch(self, inputs):\n",
    "    scores = self._model.predict_on_batch(inputs)\n",
    "    return self._transform.transform(scores)[:, :self._num_top_features]\n",
    "\n",
    "\n",
    "# TODO(avsec): Add feature description: Either PCX, or full names.\n",
    "\n",
    "\n",
    "# @title `variant_centered_sequences`\n",
    "\n",
    "class FastaStringExtractor:\n",
    "\n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "    #import pd.Interval as Interval\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# @title `plot_tracks`\n",
    "\n",
    "def plot_tracks(tracks, interval, height=1.5):\n",
    "  fig, axes = plt.subplots(len(tracks), 1, figsize=(20, height * len(tracks)), sharex=True)\n",
    "  for ax, (title, y) in zip(axes, tracks.items()):\n",
    "    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y)\n",
    "    ax.set_title(title)\n",
    "    sns.despine(top=True, right=True, bottom=True)\n",
    "  ax.set_xlabel(str(interval))\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "def create_rev_complement(dna_string):\n",
    "    return(str(Seq(dna_string).reverse_complement()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_quantify_prediction_per_TSS(predictions, gene, tss_df):\n",
    "\n",
    "  '''\n",
    "\n",
    "  Parameters:\n",
    "          predicitions (A numpy array): All predictions from the track\n",
    "          gene (a gene name, character): a gene\n",
    "          tss_df: a list of dataframe of genes and their transcription start sites\n",
    "  Returns:\n",
    "          A dictionary of cage experiment predictions and a list of transcription start sites\n",
    "\n",
    "  '''\n",
    "\n",
    "  output = dict()\n",
    "  for tdf in tss_df:\n",
    "    if gene not in tdf.genes.values:\n",
    "      continue\n",
    "    gene_tss_list = tdf[tdf.genes == gene].txStart_Sites.apply(str).values\n",
    "    gene_tss_list = [t.split(', ') for t in gene_tss_list]\n",
    "    gene_tss_list = [int(item) for nestedlist in gene_tss_list for item in nestedlist]\n",
    "    gene_tss_list = list(set(gene_tss_list))\n",
    "  output['cage_predictions'] = predictions[:, 5110] # a numpy array\n",
    "  output['gene_TSS'] = gene_tss_list # a list\n",
    "\n",
    "\n",
    "  return(output) # a dictionary\n",
    "\n",
    "def quantify_prediction_per_TSS(low_range, TSS, cage_predictions):\n",
    "\n",
    "  '''\n",
    "  Parameters:\n",
    "          low_range (int): The lower interval\n",
    "          TSS (list of integers): A list of TSS for a gene\n",
    "          cage_predictions: A 1D numpy array or a vector of predictions from enformer corresponding to track 5110 or CAGE predictions\n",
    "  Returns:\n",
    "          A dictionary of gene expression predictions for each TSS for a gene\n",
    "    '''\n",
    "  tss_predictions = dict()\n",
    "  for tss in TSS:\n",
    "    bin_start = low_range + ((768 + 320) * 128)\n",
    "    count = -1\n",
    "    while bin_start < tss:\n",
    "      bin_start = bin_start + 128\n",
    "      count += 1\n",
    "    if count >= len(cage_predictions)-1:\n",
    "      continue\n",
    "    cage_preds = cage_predictions[count - 1] + cage_predictions[count] + cage_predictions[count + 1]\n",
    "    tss_predictions[tss] = cage_preds\n",
    "\n",
    "  return(tss_predictions)\n",
    "\n",
    "def collect_intervals(chromosomes = [\"22\"], gene_list=None):\n",
    "\n",
    "  '''\n",
    "    Parameters :\n",
    "      chromosomes : a list of chromosome numbers; each element should be a string format\n",
    "      gene_list : a list of genes; the genes should be located on those chromosomes\n",
    "\n",
    "    Returns :\n",
    "      A dictionary of genes (from gene_list) and their intervals within their respective chromosomes\n",
    "  '''\n",
    "\n",
    "  gene_intervals = {} # Collect intervals for our genes of interest\n",
    "\n",
    "  for chrom in chromosomes:\n",
    "    with open(\"/home/s1mi/enformer-tutorial/gene_chroms/gene_\"+ chrom + \".txt\", \"r\") as chrom_genes:\n",
    "      for line in chrom_genes:\n",
    "        split_line = line.strip().split(\"\\t\")\n",
    "        gene_intervals[split_line[2]] = [\n",
    "                                          split_line[0],\n",
    "                                          int(split_line[3]),\n",
    "                                          int(split_line[4])\n",
    "                                        ]\n",
    "\n",
    "  if isinstance(gene_list, list): # if the user has supplied a list of genes they are interested in\n",
    "    use_genes = dict((k, gene_intervals[k]) for k in gene_list if k in gene_intervals)\n",
    "    return(use_genes)\n",
    "  elif isinstance(gene_list, type(None)):\n",
    "    return(gene_intervals)\n",
    "\n",
    "\n",
    "def run_predictions(gene_intervals, tss_dataframe, individuals_list=None):\n",
    "  '''\n",
    "  Parameters :\n",
    "    gene_intervals : the results from calling `collect_intervals`\n",
    "    tss_dataframe : a list of the TSSs dataframes i.e. the TSS for the genes in the chromosomes\n",
    "    individuals_list : a list of individuals on which we want to make predictions; defaults to None\n",
    "\n",
    "  Returns :\n",
    "    A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n",
    "  '''\n",
    "\n",
    "  gene_output = dict()\n",
    "  gene_predictions = dict()\n",
    "\n",
    "  for gene in gene_intervals.keys():\n",
    "    gene_interval = gene_intervals[gene]\n",
    "    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n",
    "                                        gene_interval[1],\n",
    "                                        gene_interval[2]) # creates an interval to select the right sequences\n",
    "    target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n",
    "    window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n",
    "    try:\n",
    "      cur_gene_vars = pd.read_csv(\"/home/s1mi/enformer-tutorial/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n",
    "    except:\n",
    "      continue\n",
    "    individual_results = dict()\n",
    "    individual_prediction = dict()\n",
    "\n",
    "    if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n",
    "      use_individuals = individuals_list\n",
    "    elif isinstance(individuals_list, type(None)):\n",
    "      use_individuals = cur_gene_vars.columns[4:]\n",
    "\n",
    "    for individual in use_individuals:\n",
    "      print('Currently on gene {}, and predicting on individual {}...'.format(gene, individual))\n",
    "      # two haplotypes per individual\n",
    "      haplo_1 = list(target_fa[:])\n",
    "      haplo_2 = list(target_fa[:])\n",
    "\n",
    "      ref_mismatch_count = 0\n",
    "      for i,row in cur_gene_vars.iterrows():\n",
    "\n",
    "        geno = row[individual].split(\"|\")\n",
    "        if (row[\"POS\"]-window_coords.start-1) >= len(haplo_2):\n",
    "          continue\n",
    "        if (row[\"POS\"]-window_coords.start-1) < 0:\n",
    "          continue\n",
    "        if geno[0] == \"1\":\n",
    "          haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n",
    "        if geno[1] == \"1\":\n",
    "          haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n",
    "\n",
    "      # predict on the individual's two haplotypes\n",
    "      prediction_1 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_1))[np.newaxis])['human'][0]\n",
    "      prediction_2 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_2))[np.newaxis])['human'][0]\n",
    "\n",
    "      temp_predictions = [prediction_1[:, 5110], prediction_2[:, 5110]] # CAGE predictions we are interested in\n",
    "      individual_prediction[individual] = temp_predictions\n",
    "\n",
    "      # Calculate TSS CAGE expression which correspond to column 5110 of the predictions above\n",
    "      temp_list = list()\n",
    "\n",
    "      pred_prepared_1 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_1, gene=gene, tss_df=tss_dataframe)\n",
    "      tss_predictions_1 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_1['gene_TSS'], cage_predictions=pred_prepared_1['cage_predictions'])\n",
    "\n",
    "      pred_prepared_2 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_2, gene=gene, tss_df=tss_dataframe)\n",
    "      tss_predictions_2 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_2['gene_TSS'], cage_predictions=pred_prepared_2['cage_predictions'])\n",
    "\n",
    "      temp_list.append(tss_predictions_1)\n",
    "      temp_list.append(tss_predictions_2) # results here are a dictionary for each TSS for each haplotype\n",
    "\n",
    "      individual_results[individual] = temp_list # save for the individual\n",
    "\n",
    "    gene_output[gene] = individual_results\n",
    "    gene_predictions[gene] = individual_prediction\n",
    "\n",
    "  return([gene_output, gene_predictions])\n",
    "\n",
    "\n",
    "def collect_target_intervals(gene_intervals):\n",
    "\n",
    "  '''\n",
    "  Returns a dictionary of Interval objects (from kipoiseq) for each gene corresponding to the locations of the gene\n",
    "  '''\n",
    "\n",
    "  target_intervals_dict = dict()\n",
    "\n",
    "  for gene in gene_intervals.keys():\n",
    "    gene_interval = gene_intervals[gene]\n",
    "    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n",
    "                                        gene_interval[1],\n",
    "                                        gene_interval[2])\n",
    "    target_intervals_dict[gene] = target_interval\n",
    "\n",
    "  return(target_intervals_dict)\n",
    "\n",
    "def prepare_for_plot_tracks(gene, individual, all_predictions, chromosome=['22']):\n",
    "\n",
    "  '''\n",
    "  This returns a dictionary of gene tracks and gene intervals, prepared for the function plot_tracks.\n",
    "\n",
    "  Parameters:\n",
    "    - gene\n",
    "    - individual\n",
    "    - all_predictions\n",
    "  '''\n",
    "\n",
    "  haplo_predictions = all_predictions[gene][individual]\n",
    "  gene_tracks = {gene + ' | ' + individual + ' | haplotype 1': np.log10(1 + haplo_predictions[0]),\n",
    "                gene + ' | ' + individual + ' | haplotype 2': np.log10(1 + haplo_predictions[1])}\n",
    "\n",
    "  gene_intervals = collect_intervals(chromosomes=chromosome, gene_list=[gene])\n",
    "  gene_intervals = collect_target_intervals(gene_intervals)\n",
    "\n",
    "  output = dict()\n",
    "  output['gene_tracks'] = gene_tracks\n",
    "  output['gene_intervals'] = gene_intervals[gene]\n",
    "\n",
    "  return(output)\n",
    "\n",
    "def check_individuals(path_to_bed_file, list_of_individuals):\n",
    "\n",
    "  '''\n",
    "  Checks if an individual is missing in bed variation files.\n",
    "  These individuals should be removed prior to training\n",
    "  '''\n",
    "\n",
    "  myfile = open(path_to_bed_file, 'r')\n",
    "  myline = myfile.readline()\n",
    "  bed_names = myline.split('\\t')[4:]\n",
    "  myfile.close()\n",
    "\n",
    "  if set(list_of_individuals).issubset(set(bed_names)) == False:\n",
    "    missing = list(set(list_of_individuals).difference(bed_names))\n",
    "    print('This (or these) individual(s) is/are not present: {}'.format(missing))\n",
    "  else:\n",
    "    missing = []\n",
    "    print('All individuals are present in the bed file.')\n",
    "\n",
    "  return(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geno_to_seq(gene, individual):\n",
    "      # two haplotypes per individual\n",
    "  haplo_1 = list(target_fa[:])\n",
    "  haplo_2 = list(target_fa[:])\n",
    "\n",
    "  ref_mismatch_count = 0\n",
    "  for i,row in cur_gene_vars.iterrows():\n",
    "\n",
    "    geno = row[individual].split(\"|\")\n",
    "    if (row[\"POS\"]-window_coords.start-1) >= len(haplo_2):\n",
    "      continue\n",
    "    if (row[\"POS\"]-window_coords.start-1) < 0:\n",
    "      continue\n",
    "    if geno[0] == \"1\":\n",
    "      haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n",
    "    if geno[1] == \"1\":\n",
    "      haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n",
    "  return haplo_1, haplo_2\n",
    "\n",
    "      # predict on the individual's two haplotypes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input data\n",
    "\n",
    "We want to predict epigenome around ERAP2 TSS on chromosome 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>TargetID</th>\n",
       "      <th>Chr</th>\n",
       "      <th>Coord</th>\n",
       "      <th>HG00096</th>\n",
       "      <th>HG00097</th>\n",
       "      <th>HG00099</th>\n",
       "      <th>HG00100</th>\n",
       "      <th>HG00101</th>\n",
       "      <th>...</th>\n",
       "      <th>NA20810</th>\n",
       "      <th>NA20811</th>\n",
       "      <th>NA20812</th>\n",
       "      <th>NA20813</th>\n",
       "      <th>NA20814</th>\n",
       "      <th>NA20815</th>\n",
       "      <th>NA20816</th>\n",
       "      <th>NA20819</th>\n",
       "      <th>NA20826</th>\n",
       "      <th>NA20828</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000223972.4</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>ENSG00000223972.4</td>\n",
       "      <td>1</td>\n",
       "      <td>11869</td>\n",
       "      <td>0.320818</td>\n",
       "      <td>0.344202</td>\n",
       "      <td>0.354225</td>\n",
       "      <td>0.478064</td>\n",
       "      <td>-0.102815</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008605</td>\n",
       "      <td>0.384489</td>\n",
       "      <td>0.581284</td>\n",
       "      <td>0.513981</td>\n",
       "      <td>0.667449</td>\n",
       "      <td>0.350890</td>\n",
       "      <td>0.186103</td>\n",
       "      <td>-0.037976</td>\n",
       "      <td>0.405439</td>\n",
       "      <td>0.199143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000227232.3</td>\n",
       "      <td>WASH7P</td>\n",
       "      <td>ENSG00000227232.3</td>\n",
       "      <td>1</td>\n",
       "      <td>29806</td>\n",
       "      <td>33.714457</td>\n",
       "      <td>20.185174</td>\n",
       "      <td>18.095407</td>\n",
       "      <td>24.100871</td>\n",
       "      <td>29.018719</td>\n",
       "      <td>...</td>\n",
       "      <td>30.980194</td>\n",
       "      <td>34.086207</td>\n",
       "      <td>39.678442</td>\n",
       "      <td>29.643513</td>\n",
       "      <td>27.120420</td>\n",
       "      <td>29.121624</td>\n",
       "      <td>31.117198</td>\n",
       "      <td>32.047074</td>\n",
       "      <td>22.798959</td>\n",
       "      <td>23.563874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000243485.1</td>\n",
       "      <td>MIR1302-11</td>\n",
       "      <td>ENSG00000243485.1</td>\n",
       "      <td>1</td>\n",
       "      <td>29554</td>\n",
       "      <td>0.240408</td>\n",
       "      <td>0.157456</td>\n",
       "      <td>0.218806</td>\n",
       "      <td>0.320878</td>\n",
       "      <td>0.067833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065940</td>\n",
       "      <td>0.228784</td>\n",
       "      <td>0.140642</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>0.273821</td>\n",
       "      <td>0.286311</td>\n",
       "      <td>0.324060</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.255288</td>\n",
       "      <td>0.157440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000238009.2</td>\n",
       "      <td>RP11-34P13.7</td>\n",
       "      <td>ENSG00000238009.2</td>\n",
       "      <td>1</td>\n",
       "      <td>133566</td>\n",
       "      <td>0.328272</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>0.090064</td>\n",
       "      <td>0.420443</td>\n",
       "      <td>0.220269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274071</td>\n",
       "      <td>0.384179</td>\n",
       "      <td>0.533693</td>\n",
       "      <td>0.307221</td>\n",
       "      <td>0.307367</td>\n",
       "      <td>0.400278</td>\n",
       "      <td>0.612321</td>\n",
       "      <td>0.666633</td>\n",
       "      <td>0.281138</td>\n",
       "      <td>1.346129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000239945.1</td>\n",
       "      <td>RP11-34P13.8</td>\n",
       "      <td>ENSG00000239945.1</td>\n",
       "      <td>1</td>\n",
       "      <td>91105</td>\n",
       "      <td>0.332171</td>\n",
       "      <td>-0.032164</td>\n",
       "      <td>0.017323</td>\n",
       "      <td>0.424677</td>\n",
       "      <td>0.214025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347323</td>\n",
       "      <td>0.346744</td>\n",
       "      <td>0.073580</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>0.470517</td>\n",
       "      <td>0.069749</td>\n",
       "      <td>0.299353</td>\n",
       "      <td>0.090019</td>\n",
       "      <td>0.282554</td>\n",
       "      <td>-0.157170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 467 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             gene_id     gene_name           TargetID Chr   Coord    HG00096  \\\n",
       "0  ENSG00000223972.4       DDX11L1  ENSG00000223972.4   1   11869   0.320818   \n",
       "1  ENSG00000227232.3        WASH7P  ENSG00000227232.3   1   29806  33.714457   \n",
       "2  ENSG00000243485.1    MIR1302-11  ENSG00000243485.1   1   29554   0.240408   \n",
       "3  ENSG00000238009.2  RP11-34P13.7  ENSG00000238009.2   1  133566   0.328272   \n",
       "4  ENSG00000239945.1  RP11-34P13.8  ENSG00000239945.1   1   91105   0.332171   \n",
       "\n",
       "     HG00097    HG00099    HG00100    HG00101  ...    NA20810    NA20811  \\\n",
       "0   0.344202   0.354225   0.478064  -0.102815  ...   1.008605   0.384489   \n",
       "1  20.185174  18.095407  24.100871  29.018719  ...  30.980194  34.086207   \n",
       "2   0.157456   0.218806   0.320878   0.067833  ...   0.065940   0.228784   \n",
       "3   0.327932   0.090064   0.420443   0.220269  ...   0.274071   0.384179   \n",
       "4  -0.032164   0.017323   0.424677   0.214025  ...   0.347323   0.346744   \n",
       "\n",
       "     NA20812    NA20813    NA20814    NA20815    NA20816    NA20819  \\\n",
       "0   0.581284   0.513981   0.667449   0.350890   0.186103  -0.037976   \n",
       "1  39.678442  29.643513  27.120420  29.121624  31.117198  32.047074   \n",
       "2   0.140642   0.283905   0.273821   0.286311   0.324060   0.049574   \n",
       "3   0.533693   0.307221   0.307367   0.400278   0.612321   0.666633   \n",
       "4   0.073580   0.400396   0.470517   0.069749   0.299353   0.090019   \n",
       "\n",
       "     NA20826    NA20828  \n",
       "0   0.405439   0.199143  \n",
       "1  22.798959  23.563874  \n",
       "2   0.255288   0.157440  \n",
       "3   0.281138   1.346129  \n",
       "4   0.282554  -0.157170  \n",
       "\n",
       "[5 rows x 467 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr5_tss = pd.read_table('/home/s1mi/enformer-tutorial/tss_by_chr/chr5_tss_by_gene.txt', sep='\\t')\n",
    "erap2_variations = pd.read_table('/home/s1mi/enformer-tutorial/individual_beds/chr5/chr5_ERAP2.bed', sep='\\t')\n",
    "geuvadis_gene_expression = pd.read_table('https://uchicago.box.com/shared/static/5vwc7pjw9qmtv7298c4rc7bcuicoyemt.gz', sep='\\t',\n",
    "                                         dtype={'gene_id': str, 'gene_name':str, 'TargetID':str, 'Chr':str})\n",
    "geuvadis_gene_expression.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intervals = collect_intervals(chromosomes=['5'], gene_list=['ERAP2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Enformer(model_path) # here we load the model architecture.\n",
    "\n",
    "fasta_extractor = FastaStringExtractor(fasta_file) # we define a class called fasta_extractor to help us extra raw sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Predictions\n",
    "\n",
    "We'll pick one individual at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NA19160'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_individual = np.random.choice(a=geuvadis_gene_expression.columns[6:-1], replace=False) # individuals we are interested in\n",
    "rand_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = 'ERAP2'\n",
    "gene_interval = gene_intervals[gene]\n",
    "target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n",
    "                                        gene_interval[1],\n",
    "                                        gene_interval[2])\n",
    "target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))\n",
    "window_coords = target_interval.resize(SEQUENCE_LENGTH)\n",
    "cur_gene_vars = pd.read_csv(\"/home/s1mi/enformer-tutorial/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "haplo_1, haplo_2 = geno_to_seq('ERAP2', rand_individual)\n",
    "\n",
    "haplo_1_enc = one_hot_encode(\"\".join(haplo_1))[np.newaxis]\n",
    "haplo_2_enc = one_hot_encode(\"\".join(haplo_2))[np.newaxis]\n",
    "average_enc = np.add(haplo_1_enc, haplo_2_enc) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_1 = model.predict_on_batch(haplo_1_enc)['human'][0]\n",
    "prediction_2 = model.predict_on_batch(haplo_2_enc)['human'][0]\n",
    "\n",
    "pre_average = model.predict_on_batch(average_enc)['human'][0]\n",
    "post_average = (prediction_1 + prediction_2) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09901776 0.09164002 0.0699944  ... 0.00303012 0.00990325 0.01237618]\n",
      " [0.05784911 0.05089986 0.03969494 ... 0.00734875 0.02510322 0.0280255 ]\n",
      " [0.00580059 0.00483631 0.00361973 ... 0.0036824  0.00902823 0.01077321]\n",
      " ...\n",
      " [0.00023449 0.00016057 0.00016778 ... 0.00083343 0.0026698  0.00314449]\n",
      " [0.00304364 0.00254643 0.00265122 ... 0.00092347 0.00226813 0.00265463]\n",
      " [0.05069465 0.03909001 0.03585194 ... 0.00824723 0.03236783 0.0296576 ]]\n",
      "[[0.09910323 0.09164958 0.07005598 ... 0.00303381 0.00984134 0.01238221]\n",
      " [0.05783322 0.05087575 0.03971903 ... 0.00735789 0.02497963 0.0280641 ]\n",
      " [0.00579469 0.00483093 0.00361714 ... 0.00366731 0.00894659 0.01073787]\n",
      " ...\n",
      " [0.00024071 0.00016465 0.00017168 ... 0.0007882  0.00254766 0.00304421]\n",
      " [0.0030893  0.00256867 0.00267111 ... 0.00086807 0.0020461  0.00242939]\n",
      " [0.05074473 0.03918105 0.03594471 ... 0.00819363 0.03179348 0.02920263]]\n"
     ]
    }
   ],
   "source": [
    "print(pre_average)\n",
    "print(post_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing across tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(5313):\n",
    "    pre_track = pre_average[:, i]\n",
    "    post_track = post_average[:, i]\n",
    "    corr = np.corrcoef(pre_track, post_track)[0][1]\n",
    "    res.append(corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from both methods are nearly identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9910764472374001 0.999995405486603\n"
     ]
    }
   ],
   "source": [
    "print(min(res), max(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-python",
   "language": "python",
   "name": "ml-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
