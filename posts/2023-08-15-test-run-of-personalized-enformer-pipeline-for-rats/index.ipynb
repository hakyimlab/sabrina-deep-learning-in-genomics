{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Testing the Enformer pipeline with added parameters for personalized prediction on rats\n",
    "author: Sabrina Mi\n",
    "date: 8/12/23\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for a single individual and gene\n",
    "\n",
    "We chose `ENSRNOG00000054549`, centered at the TSS chr20:12118762.\n",
    "\n",
    "\n",
    "```\n",
    "conda activate enformer-predict-tools\n",
    "\n",
    "cd /Users/sabrinami/Github/shared_pipelines/enformer_pipeline\n",
    "\n",
    "python scripts/enformer_predict.py --parameters /Users/sabrinami/Github/deep-learning-in-genomics/posts/2023-08-15-test-run-of-personalized-enformer-pipeline-for-rats/local_test_personalized.json\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results to non-pipeline method\n",
    "\n",
    "### Read in h5 prediction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 14:55:53.212214: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import EnformerVCF\n",
    "import kipoiseq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/Users/sabrinami/Desktop/2022-23/tutorials/enformer_pipeline_test/predictions_folder/personalized_enformer_rat_single_gene/predictions_2023-08-15/enformer_predictions/000789972A/haplotype1/chr20_12118762_12118762_predictions.h5', 'r')\n",
    "haplotype1 = f['chr20_12118762_12118762'][()]\n",
    "f = h5py.File('/Users/sabrinami/Desktop/2022-23/tutorials/enformer_pipeline_test/predictions_folder/personalized_enformer_rat_single_gene/predictions_2023-08-15/enformer_predictions/000789972A/haplotype2/chr20_12118762_12118762_predictions.h5', 'r')\n",
    "haplotype2 = f['chr20_12118762_12118762'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haplotype1:\n",
      " [[0.24076067 0.30101207 0.5132549  ... 0.20521325 1.1217918  0.25558835]\n",
      " [0.15946281 0.20442429 0.37761706 ... 0.04465578 0.24607326 0.08344302]\n",
      " [0.15568599 0.21775411 0.4520394  ... 0.05306218 0.20978831 0.08246609]\n",
      " ...\n",
      " [0.17938398 0.22463004 0.29506153 ... 0.01107231 0.02651541 0.0338815 ]\n",
      " [0.16948122 0.2044945  0.2620006  ... 0.01690046 0.04069382 0.06031117]\n",
      " [0.15266503 0.201914   0.22262897 ... 0.02438843 0.03895664 0.05986918]]\n",
      "haplotype2:\n",
      " [[0.23317184 0.29741773 0.5182305  ... 0.20385785 1.1424272  0.26008573]\n",
      " [0.15613721 0.20323968 0.37887666 ... 0.04524086 0.257699   0.08468267]\n",
      " [0.15380262 0.21736239 0.45358157 ... 0.05439655 0.22475001 0.08432709]\n",
      " ...\n",
      " [0.17942066 0.2246648  0.29515463 ... 0.01105907 0.02650285 0.03387856]\n",
      " [0.16946748 0.20452495 0.2621123  ... 0.0168827  0.04067391 0.06034191]\n",
      " [0.15272975 0.20209791 0.22299151 ... 0.0243816  0.03896997 0.05996798]]\n"
     ]
    }
   ],
   "source": [
    "print(\"haplotype1:\\n\", haplotype1)\n",
    "print(\"haplotype2:\\n\", haplotype2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run non-pipeline Enformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = '/Users/sabrinami/Desktop/2022-23/tutorials/enformer_pipeline_test/rn7_data/rn7_genome.fasta'\n",
    "fasta_extractor = EnformerVCF.FastaStringExtractor(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/sabrinami/enformer_pipeline_test/rn7_data/chr20.vcf.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## read vcf and encode haplotypes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m target_interval \u001b[39m=\u001b[39m kipoiseq\u001b[39m.\u001b[39mInterval(\u001b[39m\"\u001b[39m\u001b[39mchr20\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m12118762\u001b[39m, \u001b[39m12118762\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m chr20_vcf \u001b[39m=\u001b[39m EnformerVCF\u001b[39m.\u001b[39;49mread_vcf(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/sabrinami/enformer_pipeline_test/rn7_data/chr20.vcf.gz\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m haplo1, haplo2 \u001b[39m=\u001b[39m EnformerVCF\u001b[39m.\u001b[39mvcf_to_seq(target_interval, \u001b[39m'\u001b[39m\u001b[39m000789972A\u001b[39m\u001b[39m'\u001b[39m, chr20_vcf, fasta_extractor)\n\u001b[1;32m      5\u001b[0m haplo1_enc \u001b[39m=\u001b[39m EnformerVCF\u001b[39m.\u001b[39mone_hot_encode(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(haplo1))[np\u001b[39m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/Github/deep-learning-in-genomics/posts/2023-08-15-test-run-of-personalized-enformer-pipeline-for-rats/EnformerVCF.py:148\u001b[0m, in \u001b[0;36mread_vcf\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_vcf\u001b[39m(path):\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mwith\u001b[39;00m gzip\u001b[39m.\u001b[39;49mopen(path, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    149\u001b[0m         lines \u001b[39m=\u001b[39m [l \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m f \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m l\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m##\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m    151\u001b[0m         io\u001b[39m.\u001b[39mStringIO(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(lines)),\n\u001b[1;32m    152\u001b[0m         dtype\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39m#CHROM\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPOS\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mint\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mID\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mREF\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mALT\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    153\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mQUAL\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFILTER\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m},\n\u001b[1;32m    154\u001b[0m         sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39m#CHROM\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mCHROM\u001b[39m\u001b[39m'\u001b[39m})\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/gzip.py:58\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m gz_mode \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filename, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m, os\u001b[39m.\u001b[39mPathLike)):\n\u001b[0;32m---> 58\u001b[0m     binary_file \u001b[39m=\u001b[39m GzipFile(filename, gz_mode, compresslevel)\n\u001b[1;32m     59\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(filename, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(filename, \u001b[39m\"\u001b[39m\u001b[39mwrite\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     60\u001b[0m     binary_file \u001b[39m=\u001b[39m GzipFile(\u001b[39mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m fileobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmyfileobj \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, mode \u001b[39mor\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fileobj, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/sabrinami/enformer_pipeline_test/rn7_data/chr20.vcf.gz'"
     ]
    }
   ],
   "source": [
    "## read vcf and encode haplotypes\n",
    "target_interval = kipoiseq.Interval(\"chr20\", 12118762, 12118762)\n",
    "chr20_vcf = EnformerVCF.read_vcf(\"/Users/sabrinami/enformer_pipeline_test/rn7_data/chr20.vcf.gz\")\n",
    "haplo1, haplo2 = EnformerVCF.vcf_to_seq(target_interval, '000789972A', chr20_vcf, fasta_extractor)\n",
    "haplo1_enc = EnformerVCF.one_hot_encode(\"\".join(haplo1))[np.newaxis]\n",
    "haplo2_enc = EnformerVCF.one_hot_encode(\"\".join(haplo2))[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run predictions\n",
    "prediction1 = EnformerVCF.model.predict_on_batch(haplo1_enc)['human'][0]\n",
    "prediction2 = EnformerVCF.model.predict_on_batch(haplo2_enc)['human'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 differences between haplotype1 matrices and 0 differences between haplotype2 matrices.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", sum(sum(haplotype1 != prediction1)), \"differences between haplotype1 matrices and\", sum(sum(haplotype2 != prediction2)), \"differences between haplotype2 matrices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline outputs are the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test mouse head on reference genome\n",
    "\n",
    "```\n",
    "conda activate enformer-predict-tools\n",
    "\n",
    "cd /Users/sabrinami/Github/shared_pipelines/enformer_pipeline\n",
    "\n",
    "python scripts/enformer_predict.py --parameters /Users/sabrinami/Github/deep-learning-in-genomics/posts/2023-08-15-test-run-of-personalized-enformer-pipeline-for-rats/local_test_reference.json\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Compare results to non-pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (896, 1643)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "## Read prediction file\n",
    "f = h5py.File(\"/Users/sabrinami/Desktop/2022-23/tutorials/enformer_pipeline_test/predictions_folder/reference_enformer_rat_single_gene/predictions_2023-08-26/enformer_predictions/reference_enformer_rat/haplotype0/chr20_12118762_12118762_predictions.h5\", \"r\")\n",
    "haplotype0 = f[\"chr20_12118762_12118762\"][()]\n",
    "print(\"shape:\", haplotype0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 393216\n",
    "target_interval = kipoiseq.Interval(\"chr20\", 12118762, 12118762)\n",
    "sequence_one_hot = EnformerVCF.one_hot_encode(fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH)))\n",
    "predictions = EnformerVCF.model.predict_on_batch(sequence_one_hot[np.newaxis])['mouse'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThere are\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m(\u001b[39msum\u001b[39m(pred \u001b[39m!=\u001b[39m predictions)), \u001b[39m\"\u001b[39m\u001b[39mdifferences between pipeline and non-pipeline outputs.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"There are\", sum(sum(pred != predictions)), \"differences between pipeline and non-pipeline outputs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
