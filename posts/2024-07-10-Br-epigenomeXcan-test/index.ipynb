{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: EpigenomeXcan test on Br rats\n",
    "author: Sabrina Mi\n",
    "date: 7/10/2024\n",
    "description: Calculate associations between predicted gene expression in adipose tissue and BMI to identify significant gene, while I figure out high to scale up predicting epigenome step.\n",
    "---\n",
    "\n",
    "CPU times: \n",
    "\n",
    "1. Compute founders matrix (n_genes, 8)\n",
    "    * 3190 genes: ~110s\n",
    "2. Compute samples matrix (n_samples, n_genes, 8):\n",
    "    * 3190 genes, 1 sample: ~4s\n",
    "    * 3190 genes, 10 samples: ~40s\n",
    "\n",
    "GPU times, combined steps 1 & 2:\n",
    "1. Old code\n",
    "    * 3190 genes, 340 samples: 32 minutes\n",
    "2. New code removing inner foor loop\n",
    "    * 1592 genes, 340 samples: 2 min 30 sec\n",
    "    * 1575 genes, 340 samples: 2 min 5 sec\n",
    "    * 19696 genes, 340 samples: 22 min 30 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 00:40:22.787012: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 00:40:30.021105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/opt/cray/pe/gcc/11.2.0/snos/lib64:/opt/cray/pe/papi/6.0.0.14/lib64:/opt/cray/libfabric/1.11.0.4.125/lib64:/dbhome/db2cat/sqllib/lib64:/dbhome/db2cat/sqllib/lib64/gskit:/dbhome/db2cat/sqllib/lib32:/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:/soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/soft/perftools/darshan/darshan-3.4.4/lib:/opt/cray/pe/papi/7.0.1.2/lib64:/opt/cray/libfabric/1.15.2.0/lib64\n",
      "2024-08-09 00:40:30.023520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/opt/cray/pe/gcc/11.2.0/snos/lib64:/opt/cray/pe/papi/6.0.0.14/lib64:/opt/cray/libfabric/1.11.0.4.125/lib64:/dbhome/db2cat/sqllib/lib64:/dbhome/db2cat/sqllib/lib64/gskit:/dbhome/db2cat/sqllib/lib32:/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:/soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/soft/perftools/darshan/darshan-3.4.4/lib:/opt/cray/pe/papi/7.0.1.2/lib64:/opt/cray/libfabric/1.15.2.0/lib64\n",
      "2024-08-09 00:40:30.023528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "import bisect\n",
    "columns = ['ACI', 'BN', 'BUF', 'F344', 'M520', 'MR', 'WKY', 'WN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annot = pd.read_csv(\"/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/gene_mapping.txt\")\n",
    "genes_by_chrom = gene_annot.groupby('chromosome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_dir = \"/eagle/AIHPC4Edu/sabrina/Br_genotype_probabilities\"\n",
    "reference_dir = \"/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/human\"\n",
    "output_dir = \"/eagle/AIHPC4Edu/sabrina/Br_prediction_from_founders\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizing my haplotype probabilities storage is redundant, taking up extra space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "probabilities_file = f'{probabilities_dir}/chr20_probabilities.h5'\n",
    "with h5py.File(probabilities_file, 'a') as hf:\n",
    "    for dataset_name in list(hf.keys()):\n",
    "        if hf[dataset_name].shape[1] == 8:\n",
    "            continue\n",
    "        elif hf[dataset_name].shape[1] == 9:\n",
    "            # Read the dataset\n",
    "            data = hf[dataset_name][:]\n",
    "            positions = data[:, 0]  # Assuming the positions column is the first column\n",
    "            new_data = data[:, 1:]  # All columns except the first one\n",
    "            \n",
    "            # Create a temporary dataset without the positions column\n",
    "            temp_dataset_name = f\"temp_{dataset_name}\"\n",
    "            hf.create_dataset(temp_dataset_name, data=new_data)\n",
    "            \n",
    "            # Delete the original dataset\n",
    "            del hf[dataset_name]\n",
    "        \n",
    "            # Rename the temporary dataset to the original dataset name\n",
    "            hf.move(temp_dataset_name, dataset_name)\n",
    "        \n",
    "    hf.create_dataset('positions', data=positions)\n",
    "        # Store the positions vector as metadata (attribute) for the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split genes by chromosome number\n",
    "for individual, query haplotype probabilities at each gene tss, so we return an 8 x n_gene matrix. by batching by genes n_genes should be in the 1-2K range. stack to return a 3d array with dimensions n_samples x 8 x n_gene\n",
    "next query reference epigenome at each gene [446:450, CAGE_index], return 8 x n_gene matrix\n",
    "matrix multiply with something like tf.transpose(tf.tensordot(_W, _X, axes=[[1],[1]]),[1,0,2])\n",
    "https://stackoverflow.com/questions/41870228/understanding-tensordot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_epigenome_matrix(chr, genes_df, track = 5278):\n",
    "    reference_file = f'{reference_dir}/{chr}_genes.h5'\n",
    "    with h5py.File(reference_file, 'r') as ref:\n",
    "        rows = []\n",
    "        for gene in genes_df['gene']:\n",
    "            founder_predictions = ref[gene][:, 446:450, track]\n",
    "            rows.append(founder_predictions)\n",
    "        ref_matrix = np.stack(rows, axis=0)\n",
    "        ref_tensor = tf.reduce_mean(tf.convert_to_tensor(ref_matrix, dtype=tf.float32), axis=2)\n",
    "        return ref_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities_matrix(chr, genes_df, individuals):\n",
    "    probabilities_file = f'{probabilities_dir}/{chr}_probabilities.h5'\n",
    "    with h5py.File(probabilities_file, 'r') as prob:\n",
    "        positions = prob['positions'][:]\n",
    "        population_prob = []\n",
    "        indices = []\n",
    "        for tss in genes_df['tss']:\n",
    "            index = bisect.bisect_left(positions, tss)\n",
    "            if index == 0:\n",
    "                indices += [0,0]\n",
    "            elif index == len(positions):\n",
    "                indices += [index-1,index-1]\n",
    "            else: # 0 < index < len(positions)\n",
    "                indices += [index-1, index]\n",
    "        for sample in individuals:\n",
    "            dataset = prob[sample][:]\n",
    "            sample_prob = tf.convert_to_tensor(dataset[indices], dtype = tf.float32)\n",
    "            sample_prob = tf.reshape(sample_prob, (-1, 2, sample_prob.shape[1]))\n",
    "            sample_prob = tf.reduce_mean(sample_prob, axis=1)\n",
    "            population_prob.append(sample_prob)\n",
    "        prob_tensor = tf.stack(population_prob, axis=0)\n",
    "        return prob_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_epigenome(chr, genes_df, individuals, output_file, track):\n",
    "    ref_tensor = reference_epigenome_matrix(chr, genes_df, track)\n",
    "    prob_tensor = probabilities_matrix(chr, genes_df, individuals)\n",
    "    epigenome_tensor = tf.einsum('ijk,jk->ij', prob_tensor, ref_tensor)\n",
    "    epigenome_df = pd.DataFrame(epigenome_tensor.numpy(), columns=genes_df['gene'], index = individuals)\n",
    "    epigenome_df.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/eagle/AIHPC4Edu/sabrina/Br_genotype_probabilities/individuals.txt', 'r') as f:\n",
    "    individuals = f.read().splitlines()\n",
    "#pheno = pd.read_csv('/home/s1mi/enformer_rat_data/phenotypes/pheno.fam', sep = '\\t', index_col = 'IID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with CAGE Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 00:45:57.658084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/opt/cray/pe/gcc/11.2.0/snos/lib64:/opt/cray/pe/papi/6.0.0.14/lib64:/opt/cray/libfabric/1.11.0.4.125/lib64:/dbhome/db2cat/sqllib/lib64:/dbhome/db2cat/sqllib/lib64/gskit:/dbhome/db2cat/sqllib/lib32:/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:/soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/soft/perftools/darshan/darshan-3.4.4/lib:/opt/cray/pe/papi/7.0.1.2/lib64:/opt/cray/libfabric/1.15.2.0/lib64\n",
      "2024-08-09 00:45:57.659167: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1, 3190 genes: 129.08863715000916 seconds\n",
      "chr10, 1844 genes: 64.15786012192257 seconds\n",
      "chr11, 651 genes: 37.914293350069784 seconds\n",
      "chr12, 728 genes: 38.18615038192365 seconds\n",
      "chr13, 739 genes: 38.521823541028425 seconds\n",
      "chr14, 794 genes: 44.71535247191787 seconds\n",
      "chr15, 778 genes: 43.91769809497055 seconds\n",
      "chr16, 701 genes: 42.883026172057725 seconds\n",
      "chr17, 555 genes: 38.34623588703107 seconds\n",
      "chr18, 581 genes: 39.45503612293396 seconds\n",
      "chr19, 654 genes: 35.40245614293963 seconds\n",
      "chr2, 1592 genes: 162.26185088197235 seconds\n",
      "chr20, 702 genes: 40.760752159985714 seconds\n",
      "chr3, 1615 genes: 165.32191750698257 seconds\n",
      "chr4, 1575 genes: 162.78142886899877 seconds\n",
      "chr5, 1503 genes: 60.48483659804333 seconds\n",
      "chr6, 1033 genes: 50.48902957001701 seconds\n",
      "chr7, 1370 genes: 55.30841292592231 seconds\n",
      "chr8, 1289 genes: 53.40656710800249 seconds\n",
      "chr9, 982 genes: 48.54825172596611 seconds\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/human/chrX_genes.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mchr\u001b[39m, genes_df \u001b[38;5;129;01min\u001b[39;00m genes_by_chrom:\n\u001b[1;32m      2\u001b[0m     tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mpredict_epigenome\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mchr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindividuals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mchr\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_CAGE_brain__predict.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4980\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     toc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mchr\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(genes_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m genes:\u001b[39m\u001b[38;5;124m'\u001b[39m, toc \u001b[38;5;241m-\u001b[39m tic, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mpredict_epigenome\u001b[0;34m(chr, genes_df, individuals, output_file, track)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_epigenome\u001b[39m(\u001b[38;5;28mchr\u001b[39m, genes_df, individuals, output_file, track):\n\u001b[0;32m----> 2\u001b[0m     ref_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mreference_epigenome_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mchr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     prob_tensor \u001b[38;5;241m=\u001b[39m probabilities_matrix(\u001b[38;5;28mchr\u001b[39m, genes_df, individuals)\n\u001b[1;32m      4\u001b[0m     epigenome_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mijk,jk->ij\u001b[39m\u001b[38;5;124m'\u001b[39m, prob_tensor, ref_tensor)\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mreference_epigenome_matrix\u001b[0;34m(chr, genes_df, track)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreference_epigenome_matrix\u001b[39m(\u001b[38;5;28mchr\u001b[39m, genes_df, track \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5278\u001b[39m):\n\u001b[1;32m      2\u001b[0m     reference_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mchr\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_genes.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ref:\n\u001b[1;32m      4\u001b[0m         rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m genes_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgene\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/ml-python/lib/python3.10/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.conda/envs/ml-python/lib/python3.10/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/human/chrX_genes.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "for chr, genes_df in genes_by_chrom:\n",
    "    tic = time.perf_counter()\n",
    "    predict_epigenome(chr, genes_df, individuals, f'{output_dir}/{chr}_CAGE_brain__predict.txt', track = 4980)\n",
    "    toc = time.perf_counter()\n",
    "    print(f'{chr}, {len(genes_df)} genes:', toc - tic, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
