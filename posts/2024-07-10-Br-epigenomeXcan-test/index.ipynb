{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: EpigenomeXcan test on Br rats\n",
    "author: Sabrina Mi\n",
    "date: 7/10/2024\n",
    "description: Calculate associations between predicted gene expression in adipose tissue and BMI to identify significant gene, while I figure out high to scale up predicting epigenome step.\n",
    "---\n",
    "\n",
    "CPU times: \n",
    "\n",
    "1. Compute founders matrix (n_genes, 8)\n",
    "    * 3190 genes: ~110s\n",
    "2. Compute samples matrix (n_samples, n_genes, 8):\n",
    "    * 3190 genes, 1 sample: ~4s\n",
    "    * 3190 genes, 10 samples: ~40s\n",
    "\n",
    "GPU times (combined steps):\n",
    "    * 3190 genes, 340 samples: 32 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 06:09:15.855401: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-08 06:09:23.430777: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/opt/cray/pe/gcc/11.2.0/snos/lib64:/opt/cray/pe/papi/6.0.0.14/lib64:/opt/cray/libfabric/1.11.0.4.125/lib64:/dbhome/db2cat/sqllib/lib64:/dbhome/db2cat/sqllib/lib64/gskit:/dbhome/db2cat/sqllib/lib32:/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:/soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/soft/perftools/darshan/darshan-3.4.4/lib:/opt/cray/pe/papi/7.0.1.2/lib64:/opt/cray/libfabric/1.15.2.0/lib64\n",
      "2024-08-08 06:09:23.433059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/opt/cray/pe/gcc/11.2.0/snos/lib64:/opt/cray/pe/papi/6.0.0.14/lib64:/opt/cray/libfabric/1.11.0.4.125/lib64:/dbhome/db2cat/sqllib/lib64:/dbhome/db2cat/sqllib/lib64/gskit:/dbhome/db2cat/sqllib/lib32:/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:/soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/soft/perftools/darshan/darshan-3.4.4/lib:/opt/cray/pe/papi/7.0.1.2/lib64:/opt/cray/libfabric/1.15.2.0/lib64\n",
      "2024-08-08 06:09:23.433066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "import bisect\n",
    "columns = ['ACI', 'BN', 'BUF', 'F344', 'M520', 'MR', 'WKY', 'WN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annot = pd.read_csv(\"/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/gene_mapping.txt\")\n",
    "genes_by_chrom = gene_annot.groupby('chromosome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_dir = \"/eagle/AIHPC4Edu/sabrina/Br_genotype_probabilities\"\n",
    "reference_dir = \"/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/human\"\n",
    "output_dir = \"/eagle/AIHPC4Edu/sabrina/Br_prediction_from_founders\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizing my haplotype probabilities storage is redundant, taking up extra space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "probabilities_file = f'{probabilities_dir}/chr2_probabilities.h5'\n",
    "with h5py.File(probabilities_file, 'a') as hf:\n",
    "    for dataset_name in list(hf.keys()):\n",
    "        if hf[dataset_name].shape[1] == 8:\n",
    "            continue\n",
    "        elif hf[dataset_name].shape[1] == 9:\n",
    "            # Read the dataset\n",
    "            data = hf[dataset_name][:]\n",
    "            positions = data[:, 0]  # Assuming the positions column is the first column\n",
    "            new_data = data[:, 1:]  # All columns except the first one\n",
    "            \n",
    "            # Create a temporary dataset without the positions column\n",
    "            temp_dataset_name = f\"temp_{dataset_name}\"\n",
    "            hf.create_dataset(temp_dataset_name, data=new_data)\n",
    "            \n",
    "            # Delete the original dataset\n",
    "            del hf[dataset_name]\n",
    "        \n",
    "            # Rename the temporary dataset to the original dataset name\n",
    "            hf.move(temp_dataset_name, dataset_name)\n",
    "        \n",
    "    hf.create_dataset('positions', data=positions)\n",
    "        # Store the positions vector as metadata (attribute) for the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(probabilities_file, 'r') as hf:\n",
    "    print(len(hf.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split genes by chromosome number\n",
    "for individual, query haplotype probabilities at each gene tss, so we return an 8 x n_gene matrix. by batching by genes n_genes should be in the 1-2K range. stack to return a 3d array with dimensions n_samples x 8 x n_gene\n",
    "next query reference epigenome at each gene [446:450, CAGE_index], return 8 x n_gene matrix\n",
    "matrix multiply with something like tf.transpose(tf.tensordot(_W, _X, axes=[[1],[1]]),[1,0,2])\n",
    "https://stackoverflow.com/questions/41870228/understanding-tensordot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_epigenome_matrix(chr, genes_df, individuals):\n",
    "    reference_file = f'{reference_dir}/{chr}_genes.h5'\n",
    "    with h5py.File(reference_file, 'r') as ref:\n",
    "        rows = []\n",
    "        for gene in genes_df['gene']:\n",
    "            founder_predictions = ref[gene][:, 446:450, 5278]\n",
    "            rows.append(founder_predictions)\n",
    "        ref_matrix = np.stack(rows, axis=0)\n",
    "        ref_tensor = tf.reduce_mean(tf.convert_to_tensor(ref_matrix, dtype=tf.float32), axis=2)\n",
    "        return ref_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities_matrix(chr, genes_df, individuals):\n",
    "    probabilities_file = f'{probabilities_dir}/{chr}_probabilities.h5'\n",
    "    with h5py.File(probabilities_file, 'r') as prob:\n",
    "        positions = prob['positions'][:]\n",
    "        population_prob = []\n",
    "        for sample in individuals:\n",
    "            rows = []\n",
    "            for tss in genes_df['tss']:\n",
    "                index = bisect.bisect_left(positions, tss)\n",
    "                tss_prob = (prob[sample][index-1,:] + prob[sample][index,:]) / 2\n",
    "                rows.append(tss_prob)\n",
    "            sample_prob = np.vstack(rows)\n",
    "            population_prob.append(sample_prob)\n",
    "        prob_matrix = np.stack(population_prob, axis=0)\n",
    "        prob_tensor = tf.convert_to_tensor(prob_matrix, dtype = tf.float32)\n",
    "        return prob_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_epigenome(chr, genes_df, individuals, output_file):\n",
    "    ref_tensor = reference_epigenome_matrix(chr, genes_df, individuals)\n",
    "    prob_tensor = probabilities_matrix(chr, genes_df, individuals)\n",
    "    epigenome_tensor = tf.einsum('ijk,jk->ij', prob_tensor, ref_tensor)\n",
    "    epigenome_df = pd.DataFrame(epigenome_tensor.numpy(), columns=genes_df['gene'], index = individuals)\n",
    "    epigenome_df.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/eagle/AIHPC4Edu/sabrina/Br_genotype_probabilities/individuals.txt', 'r') as f:\n",
    "    individuals = f.read().splitlines()\n",
    "#pheno = pd.read_csv('/home/s1mi/enformer_rat_data/phenotypes/pheno.fam', sep = '\\t', index_col = 'IID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'positions' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m genes_df \u001b[38;5;241m=\u001b[39m genes_by_chrom\u001b[38;5;241m.\u001b[39mget_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchr2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpredict_epigenome\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindividuals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/chr2_adipose_predict.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mpredict_epigenome\u001b[0;34m(chr, genes_df, individuals, output_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_epigenome\u001b[39m(\u001b[38;5;28mchr\u001b[39m, genes_df, individuals, output_file):\n\u001b[1;32m      2\u001b[0m     ref_tensor \u001b[38;5;241m=\u001b[39m reference_epigenome_matrix(\u001b[38;5;28mchr\u001b[39m, genes_df, individuals)\n\u001b[0;32m----> 3\u001b[0m     prob_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mprobabilities_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mchr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindividuals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     epigenome_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mijk,jk->ij\u001b[39m\u001b[38;5;124m'\u001b[39m, prob_tensor, ref_tensor)\n\u001b[1;32m      5\u001b[0m     epigenome_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(epigenome_tensor\u001b[38;5;241m.\u001b[39mnumpy(), columns\u001b[38;5;241m=\u001b[39mgenes_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgene\u001b[39m\u001b[38;5;124m'\u001b[39m], index \u001b[38;5;241m=\u001b[39m individuals)\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mprobabilities_matrix\u001b[0;34m(chr, genes_df, individuals)\u001b[0m\n\u001b[1;32m      2\u001b[0m probabilities_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobabilities_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mchr\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_probabilities.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(probabilities_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m prob:\n\u001b[0;32m----> 4\u001b[0m     positions \u001b[38;5;241m=\u001b[39m \u001b[43mprob\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpositions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:]\n\u001b[1;32m      5\u001b[0m     population_prob \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m individuals:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/ml-python/lib/python3.10/site-packages/h5py/_hl/group.py:328\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 328\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:190\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'positions' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "genes_df = genes_by_chrom.get_group('chr2')\n",
    "predict_epigenome('chr2', genes_df, individuals, f'{output_dir}/chr2_adipose_predict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 06:12:22.221154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/opt/cray/pe/gcc/11.2.0/snos/lib64:/opt/cray/pe/papi/6.0.0.14/lib64:/opt/cray/libfabric/1.11.0.4.125/lib64:/dbhome/db2cat/sqllib/lib64:/dbhome/db2cat/sqllib/lib64/gskit:/dbhome/db2cat/sqllib/lib32:/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:/soft/compilers/cudatoolkit/cuda-11.8.0/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-11.8.0/lib64:/soft/libraries/trt/TensorRT-8.5.2.2.Linux.x86_64-gnu.cuda-11.8.cudnn8.6/lib:/soft/libraries/nccl/nccl_2.16.2-1+cuda11.8_x86_64/lib:/soft/libraries/cudnn/cudnn-11-linux-x64-v8.6.0.163/lib:/soft/perftools/darshan/darshan-3.4.4/lib:/opt/cray/pe/papi/7.0.1.2/lib64:/opt/cray/libfabric/1.15.2.0/lib64\n",
      "2024-08-08 06:12:22.222344: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "for chr, genes_df in genes_by_chrom:\n",
    "    predict_epigenome(chr, genes_df, individuals, f'{output_dir}/{chr}_adipose_predict.txt')\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
