{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Scaling up EpigenomeXcan: execution time, parallelization\"\n",
    "author: Sabrina Mi\n",
    "date: 1/3/2024\n",
    "---\n",
    "\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "columns = ['POS', 'ACI', 'BN', 'BUF', 'F344', 'M520', 'MR', 'WKY', 'WN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/s1mi/Github/deep-learning-in-genomics/posts/2023-11-07-HS-founder-epigenomes/Br_expressed_genes.txt\", \"r\") as f:\n",
    "    gene_list = f.read().splitlines()\n",
    "with open(\"/home/s1mi/Github/deep-learning-in-genomics/posts/2023-11-07-HS-founder-epigenomes/metadata/intervals.txt\", \"r\") as f:\n",
    "    intervals = f.read().splitlines()\n",
    "mapping = pd.DataFrame({\"gene\": gene_list, \"interval\": intervals})\n",
    "split_intervals = mapping['interval'].str.split('_')\n",
    "mapping['chromosome'] = split_intervals.str[0]\n",
    "mapping['tss'] = split_intervals.str[1]\n",
    "mapping.drop(columns=['interval']).to_csv(\"/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/gene_mapping.txt\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_dir = \"/home/s1mi/Br_genotype_probabilities\"\n",
    "reference_dir = \"/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/human\"\n",
    "project_dir = \"/eagle/AIHPC4Edu/sabrina/Br_predictions/Br_epigenomes\"\n",
    "with open(\"/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/Br_samples.txt\", \"r\") as f:\n",
    "    individuals = f.read().splitlines()\n",
    "mapping = pd.read_csv(\"/eagle/AIHPC4Edu/sabrina/Br_predictions/HS_founder_epigenomes/gene_mapping.txt\")\n",
    "genes_df = mapping[mapping['chromosome'] == 'chr1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_h5(path, predictions):\n",
    "    with h5py.File(path, \"w\") as hf:\n",
    "        for key, value in predictions.items():\n",
    "            hf[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epigenome(chr, gene, start, end, prob):\n",
    "    bins = np.linspace(start, end, 896)\n",
    "    interp_prob = []\n",
    "    for column in columns[1:]: \n",
    "        interp_prob.append(np.interp(bins, prob['POS'], prob[column]))\n",
    "    pr_matrix = np.transpose(np.array(interp_prob))\n",
    "    with h5py.File(os.path.join(reference_dir, f\"{chr}_genes.h5\"), \"r\") as hf:\n",
    "        matrix = hf[gene][:]\n",
    "    ref_matrix = np.transpose(matrix, axes=(1, 0, 2))\n",
    "    output = np.squeeze(pr_matrix[:, np.newaxis,:] @ ref_matrix, 1)\n",
    "    return output\n",
    "    \n",
    "\n",
    "def run_predictions(chr, prob, gene_annot):\n",
    "    predictions = {}\n",
    "    # interp = interpolate.interp1d(np.array(prob['POS']), np.array(prob.drop(columns=['POS'])), axis = 0)\n",
    "    start_time = time.perf_counter()\n",
    "    for index, row in gene_annot.iterrows():\n",
    "        gene = row['gene']\n",
    "        tss = row['tss']\n",
    "        start = tss - 57344\n",
    "        end = tss + 57344\n",
    "        # if (start >= prob.iloc[0,0] and end <= prob.iloc[-1,0]):\n",
    "        output = compute_epigenome(chr, gene, start, end, prob)\n",
    "        # Process genotype probabilities\n",
    "        predictions[gene] = output\n",
    "        if ((index + 1) % 200 == 0):\n",
    "            end_time = time.perf_counter()\n",
    "            print(index + 1, \"iterations:\", end_time - start_time, \"seconds\")\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 iterations: 43.178196704000584 seconds\n",
      "400 iterations: 85.30787616000089 seconds\n",
      "600 iterations: 127.37160777700046 seconds\n",
      "800 iterations: 170.39981612300107 seconds\n",
      "1000 iterations: 214.97213824600112 seconds\n",
      "1200 iterations: 258.91626574399925 seconds\n",
      "1400 iterations: 302.4928128120009 seconds\n",
      "1600 iterations: 346.4003939719987 seconds\n",
      "1800 iterations: 389.48382942399985 seconds\n",
      "2000 iterations: 433.0845548489997 seconds\n",
      "2200 iterations: 476.6690443709995 seconds\n",
      "2400 iterations: 546.7537841170015 seconds\n",
      "2600 iterations: 592.0861903549994 seconds\n",
      "2800 iterations: 658.7331474230014 seconds\n",
      "3000 iterations: 718.2645332190004 seconds\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(probabilities_dir, f\"chr1_probabilities.h5\"), \"r\") as input:\n",
    "        output_dir = os.path.join(project_dir, '0007899884')\n",
    "        if not os.path.isdir(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "        prob = pd.DataFrame(input['0007899884'][:], columns=columns)\n",
    "        predictions = run_predictions('chr1', prob, genes_df)\n",
    "        write_h5(os.path.join(output_dir, f\"{chr}_genes.h5\"), predictions) \n",
    "# print(f\"{chr}:\", len(group), \"genes...\", (end_time - start_time) // 60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy Test \n",
    "\n",
    "Using scipy's interp1d function to interpolate all 8 columns simultaneously. Generating the interpolation function costs about 20 seconds of runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epigenome(gene, start, end, interp):\n",
    "    bins = np.linspace(start, end, 896)\n",
    "    pr_matrix = interp(bins)\n",
    "    with h5py.File(os.path.join(reference_dir, f\"chr1_genes.h5\"), \"r\") as hf:\n",
    "        matrix = hf[gene][:]\n",
    "    ref_matrix = np.transpose(matrix, axes=(1, 0, 2))\n",
    "    output = np.squeeze(pr_matrix[:, np.newaxis,:] @ ref_matrix, 1)\n",
    "    return output\n",
    "def run_predictions(prob, gene_annot):\n",
    "    predictions = {}\n",
    "    interp = interp1d(np.array(prob['POS']), np.array(prob.drop(columns=['POS'])), axis = 0)\n",
    "    start_time = time.perf_counter()\n",
    "    for index, row in gene_annot.iterrows():\n",
    "        gene = row['gene']\n",
    "        tss = row['tss']\n",
    "        start = tss - 57344\n",
    "        end = tss + 57344\n",
    "        if (start >= prob.iloc[0,0] and end <= prob.iloc[-1,0]):\n",
    "            output = compute_epigenome(gene, start, end, interp)\n",
    "            # Process genotype probabilities\n",
    "            predictions[gene] = output\n",
    "            end_time = time.perf_counter()\n",
    "            if ((index + 1) % 200 == 0):\n",
    "                print(index + 1, \"iterations:\", end_time - start_time, \"seconds\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 iterations: 55.26515249814838 seconds\n",
      "400 iterations: 105.58576967194676 seconds\n",
      "600 iterations: 136.04839484021068 seconds\n",
      "800 iterations: 193.6581759629771 seconds\n",
      "1000 iterations: 254.47129005938768 seconds\n",
      "1200 iterations: 305.2362718908116 seconds\n",
      "1400 iterations: 355.68491036072373 seconds\n",
      "1600 iterations: 417.03871417138726 seconds\n",
      "1800 iterations: 469.593163177371 seconds\n",
      "2000 iterations: 522.8375322008505 seconds\n",
      "2200 iterations: 576.9442004561424 seconds\n",
      "2400 iterations: 629.3138183737174 seconds\n",
      "2600 iterations: 687.7609961153939 seconds\n",
      "2800 iterations: 739.739781155251 seconds\n",
      "3000 iterations: 797.2053201990202 seconds\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(probabilities_dir, f\"chr1_probabilities.h5\"), \"r\") as input:\n",
    "    prob = pd.DataFrame(input['000789972A'][:], columns=columns)\n",
    "    predictions = run_predictions(prob, genes_df)\n",
    "    # write_h5(os.path.join(output_dir, f\"{chr}_genes.h5\"), predictions) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Test (GPU)\n",
    "\n",
    "Neither tensorflow or torch libraries offer interpolation for the purpose I need, so I wrote my interpolation function in order to keep all of the computational steps as tensorflow operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 21:51:15.886087: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(x, xi, y):\n",
    "    j   =   tf.argsort(tf.concat((x, xi), axis=-1))\n",
    "    k   =   tf.range(len(j))\n",
    "    q   =   tf.scatter_nd(j[:, tf.newaxis], k, k.shape)\n",
    "\n",
    "    lxi =   len(xi)\n",
    "\n",
    "    r   =   q[-lxi:]-tf.range(0, lxi)\n",
    "    r   =   tf.where(xi == x[-1], q[-1:] - lxi, r)\n",
    "\n",
    "    x2  =   tf.gather(x, r)\n",
    "    x1  =   tf.gather(x, r-1)\n",
    "    y2  =   tf.gather(y, r)\n",
    "    y1  =   tf.gather(y, r-1)\n",
    "\n",
    "    u   =   (xi-x1)/(x2-x1)\n",
    "    if not tf.rank(u) == tf.rank(y1):\n",
    "        u   =   tf.expand_dims(u, axis=-1)\n",
    "\n",
    "    yi  =   (1.0-u)*y1 + u*y2\n",
    "\n",
    "    return tf.where(y1 == y2, y1, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epigenome(gene, start, end, prob):\n",
    "    x = tf.constant(prob['POS'].values)\n",
    "    y = tf.constant(prob.drop(columns=['POS']).values)\n",
    "    bins = tf.linspace(start, end, 896)\n",
    "    pr_tensor = tf.expand_dims(tf.cast(interpolate(x, bins, y), dtype=tf.float32), axis=1)\n",
    "    with h5py.File(os.path.join(reference_dir, f\"chr1_genes.h5\"), \"r\") as hf:\n",
    "        matrix = hf[gene][:]\n",
    "    ref_tensor = tf.transpose(matrix, perm=[1, 0, 2])\n",
    "    output = tf.squeeze(tf.matmul(pr_tensor, ref_tensor), axis=1)\n",
    "    return output\n",
    "def run_predictions(prob, gene_annot):\n",
    "    predictions = {}\n",
    "    start_time = time.perf_counter()\n",
    "    for index, row in gene_annot.iterrows():\n",
    "        gene = row['gene']\n",
    "        tss = row['tss']\n",
    "        start = tss - 57344\n",
    "        end = tss + 57344\n",
    "        if (start >= prob.iloc[0,0] and end <= prob.iloc[-1,0]):\n",
    "            output = compute_epigenome(gene, start, end, prob)\n",
    "            # Process genotype probabilities\n",
    "            predictions[gene] = output\n",
    "            end_time = time.perf_counter()\n",
    "            if ((index + 1) % 200 == 0):\n",
    "                print(index + 1, \"iterations:\", end_time - start_time, \"seconds\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 21:51:44.193582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38167 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n",
      "2024-01-10 21:51:44.197736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 37815 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-01-10 21:51:44.204366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 37755 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:85:00.0, compute capability: 8.0\n",
      "2024-01-10 21:51:44.205973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 37755 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c7:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(probabilities_dir, f\"chr1_probabilities.h5\"), \"r\") as input:\n",
    "    output_dir = os.path.join(project_dir, '0007899884')\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    prob = pd.DataFrame(input['000789FF64'][:], columns=columns)\n",
    "    predictions = run_predictions(prob, genes_df)\n",
    "    write_h5(os.path.join(output_dir, f\"{chr}_genes.h5\"), predictions) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08767378 0.09323303 0.16627961 ... 0.00949302 0.03075832 0.03259552]\n",
      " [0.08988153 0.09385183 0.13803922 ... 0.00846795 0.02565644 0.02787809]\n",
      " [0.0828562  0.08802018 0.08945152 ... 0.00512026 0.01920758 0.01718544]\n",
      " ...\n",
      " [0.08135339 0.08957597 0.0973008  ... 0.00999105 0.03571409 0.02636748]\n",
      " [0.09193078 0.0944492  0.10272115 ... 0.00973209 0.03738421 0.02245922]\n",
      " [0.09127819 0.08846645 0.08769749 ... 0.01205442 0.0357308  0.02092708]]\n"
     ]
    }
   ],
   "source": [
    "def compute_epigenome(gene, start, end, interp):\n",
    "    bins = np.linspace(start, end, 896)\n",
    "    pr_matrix = interp(bins)\n",
    "    with h5py.File(os.path.join(reference_dir, f\"chr1_genes.h5\"), \"r\") as hf:\n",
    "        matrix = hf[gene][:]\n",
    "    ref_matrix = np.transpose(matrix, axes=(1, 0, 2))\n",
    "    output = np.squeeze(pr_matrix[:, np.newaxis,:] @ ref_matrix, 1)\n",
    "    return output\n",
    "\n",
    "with h5py.File(os.path.join(probabilities_dir, f\"chr1_probabilities.h5\"), \"r\") as input:\n",
    "    prob = pd.DataFrame(input['000789FF64'][:], columns=columns)\n",
    "    interp = interp1d(np.array(prob['POS']), np.array(prob.drop(columns=['POS'])), axis = 0)\n",
    "    start_time = time.perf_counter()\n",
    "    for index, row in genes_df.iterrows():\n",
    "        gene = row['gene']\n",
    "        tss = row['tss']\n",
    "        start = tss - 57344\n",
    "        end = tss + 57344\n",
    "        if (start >= prob.iloc[0,0] and end <= prob.iloc[-1,0]):\n",
    "            output = compute_epigenome(gene, start, end, interp)\n",
    "            # Process genotype probabilities\n",
    "            predictions[gene] = output\n",
    "            end_time = time.perf_counter()\n",
    "            if ((index + 1) % 200 == 0):\n",
    "                print(index + 1, \"iterations:\", end_time - start_time, \"seconds\")\n",
    "        break\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
